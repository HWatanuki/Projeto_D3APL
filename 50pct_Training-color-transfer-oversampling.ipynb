{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-07T05:37:40.567334Z","iopub.execute_input":"2023-06-07T05:37:40.568288Z","iopub.status.idle":"2023-06-07T05:37:45.548001Z","shell.execute_reply.started":"2023-06-07T05:37:40.568246Z","shell.execute_reply":"2023-06-07T05:37:45.547055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1. Dataset**","metadata":{}},{"cell_type":"markdown","source":"# 1.1 Profiling","metadata":{}},{"cell_type":"code","source":"ls ../input/ifsp-d3apl-2023-face-recognition/train/train/","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:38:05.034366Z","iopub.execute_input":"2023-06-07T05:38:05.034715Z","iopub.status.idle":"2023-06-07T05:38:05.984830Z","shell.execute_reply.started":"2023-06-07T05:38:05.034687Z","shell.execute_reply":"2023-06-07T05:38:05.983695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndataset_folder = '../input/ifsp-d3apl-2023-face-recognition/train/train/'\n\nclass_folders = sorted(os.listdir(dataset_folder))\n\n\nprint(class_folders)\nprint(f'Number of class: {len(class_folders)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:38:18.014252Z","iopub.execute_input":"2023-06-07T05:38:18.014600Z","iopub.status.idle":"2023-06-07T05:38:18.021293Z","shell.execute_reply.started":"2023-06-07T05:38:18.014574Z","shell.execute_reply":"2023-06-07T05:38:18.020211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show me the class proportions: number of samples per class\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    \n    class_img_filenames = os.listdir(full_class_folder)\n    print(f'Number of Images for Class \"{class_folder}\": {len(class_img_filenames)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:38:20.920384Z","iopub.execute_input":"2023-06-07T05:38:20.921101Z","iopub.status.idle":"2023-06-07T05:38:20.990929Z","shell.execute_reply.started":"2023-06-07T05:38:20.921066Z","shell.execute_reply":"2023-06-07T05:38:20.990054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\n# List of directories\n#directories = ['dir1', 'dir2', 'dir3']\n\n# Dictionary to store directory and file count\nfile_counts = {}\n\n# Count files in each directory\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    file_counts[class_folder] = len(glob.glob(os.path.join(full_class_folder, '*')))\n\n# Sort file counts by value in descending order\nsorted_counts = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)\n\nprint(sorted_counts)\n\n# Print the sorted file counts\n#for class_folder, count in sorted_counts:\n#    print(f\"{class_folder}: {count} files\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.2 Duplicate the training data folder for oversampling","metadata":{}},{"cell_type":"code","source":"import shutil\n# Set the paths for the input and output directories\ninput_dir = dataset_folder\ndata_dir = '../working/oversampled'\n\n# Duplicate the entire folder\nshutil.copytree(input_dir, data_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:38:37.065406Z","iopub.execute_input":"2023-06-07T05:38:37.065751Z","iopub.status.idle":"2023-06-07T05:39:21.650217Z","shell.execute_reply.started":"2023-06-07T05:38:37.065722Z","shell.execute_reply":"2023-06-07T05:39:21.649185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\n# List of directories\n#directories = ['dir1', 'dir2', 'dir3']\n\n# Dictionary to store directory and file count\nfile_counts = {}\n\nclass_folders = sorted(os.listdir(data_dir))\n\n# Count files in each directory\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(data_dir, class_folder)\n    file_counts[class_folder] = len(glob.glob(os.path.join(full_class_folder, '*')))\n\n# Sort file counts by value in descending order\nsorted_counts = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)\n\nprint(sorted_counts)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image \nimport PIL \n\n# Set the desired number of samples per class\ndesired_samples = 350\n\n# Create an instance of the ImageDataGenerator\ndata_generator = ImageDataGenerator(\n    #rescale=1./255,  # Normalize pixel values to [0, 1]\n    rotation_range=20,  # Randomly rotate images within the range of 20 degrees\n    #width_shift_range=0.1,  # Randomly shift the width of images by 10%\n    #height_shift_range=0.1,  # Randomly shift the height of images by 10%\n    shear_range=0.2,  # Apply random shear transformations\n    zoom_range=0.2,  # Apply random zoom transformations\n    horizontal_flip=True,  # Randomly flip images horizontally\n    fill_mode='nearest'  # Fill any newly created pixels after rotation or shifting\n)\n\n# Iterate through the folders representing each class\nfor class_folder in os.listdir(data_dir):\n    class_folder_path = os.path.join(data_dir, class_folder)\n    \n    if os.path.isdir(class_folder_path):\n        # Get the list of images in the current class folder\n        images = os.listdir(class_folder_path)\n        \n        # Calculate the number of existing samples in the class\n        existing_samples = len(images)\n        \n        if existing_samples < desired_samples:\n            # Calculate the number of additional samples needed\n            additional_samples = desired_samples - existing_samples\n            \n            # Randomly select images from the existing samples\n            #selected_images = random.sample(images, additional_samples)\n            \n            # Create a data generator for the current class folder\n            generator = data_generator.flow_from_directory(\n                directory=data_dir,\n                target_size=(100, 100),  # Adjust the target size as per your requirements\n                batch_size=1,\n                class_mode='categorical',\n                classes=[class_folder],\n                shuffle=True,\n                save_to_dir=class_folder_path, \n                save_prefix='aug-',\n                save_format='jpg'\n            )\n            \n            # Generate additional samples using the data generator\n            for i in range(additional_samples):\n                batch = next(generator)\n                imagem = batch[0]\n                \n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:39:37.295999Z","iopub.execute_input":"2023-06-07T05:39:37.296384Z","iopub.status.idle":"2023-06-07T05:40:28.844490Z","shell.execute_reply.started":"2023-06-07T05:39:37.296350Z","shell.execute_reply":"2023-06-07T05:40:28.843562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\n# List of directories\n#directories = ['dir1', 'dir2', 'dir3']\n\n# Dictionary to store directory and file count\nfile_counts = {}\n\nclass_folders = sorted(os.listdir(data_dir))\n\n# Count files in each directory\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(data_dir, class_folder)\n    file_counts[class_folder] = len(glob.glob(os.path.join(full_class_folder, '*')))\n\n# Sort file counts by value in descending order\nsorted_counts = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)\n\nprint(sorted_counts)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:40:53.813845Z","iopub.execute_input":"2023-06-07T05:40:53.814224Z","iopub.status.idle":"2023-06-07T05:40:53.925943Z","shell.execute_reply.started":"2023-06-07T05:40:53.814186Z","shell.execute_reply":"2023-06-07T05:40:53.925025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.3 Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"max_n_samples_per_class = 300","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:40:59.837718Z","iopub.execute_input":"2023-06-07T05:40:59.838072Z","iopub.status.idle":"2023-06-07T05:40:59.842663Z","shell.execute_reply.started":"2023-06-07T05:40:59.838044Z","shell.execute_reply":"2023-06-07T05:40:59.841652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\n\ndata_dir = '../working/oversampled'\ndataset_folder = data_dir\nclass_folders = sorted(os.listdir(dataset_folder))\n\n# OPTIONAL: just to get the same selected images\nrandom.seed(42)\n\nimg_full_paths = []\nimg_classes = []\n\nfor class_folder in class_folders:\n    img_class = class_folder  # english\n    print(f'Class: {img_class}')  # italiano\n    \n    # translated class\n    #img_class = translate[class_folder]  # english\n    #print(f'Translation: {img_class}')  # italiano\n    \n    # get the full class folder pathname\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    print(full_class_folder)\n    \n    # get all image filenames (without their parent dir) for the current class/animal\n    class_img_filenames = sorted(os.listdir(full_class_folder))\n    print(len(class_img_filenames))\n    \n    #### undersampling from scratch\n    ### one possible strategy to select `max_n_samples_per_class` of samples randomly\n    # random.shuffle(class_img_filenames)\n    # class_img_filenames = class_img_filenames[:max_n_samples_per_class]\n\n    class_img_filenames = random.sample(class_img_filenames, max_n_samples_per_class)\n    print(f'Number of images: {len(class_img_filenames)}')\n    \n    for img_filename in class_img_filenames:\n        full_img_path = os.path.join(full_class_folder, img_filename)\n        \n        img_full_paths.append(full_img_path)\n        img_classes.append(img_class)\n    \n    print()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:02.165667Z","iopub.execute_input":"2023-06-07T05:41:02.166031Z","iopub.status.idle":"2023-06-07T05:41:02.278866Z","shell.execute_reply.started":"2023-06-07T05:41:02.166001Z","shell.execute_reply":"2023-06-07T05:41:02.277901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(img_full_paths))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:09.389654Z","iopub.execute_input":"2023-06-07T05:41:09.390029Z","iopub.status.idle":"2023-06-07T05:41:09.395367Z","shell.execute_reply.started":"2023-06-07T05:41:09.389999Z","shell.execute_reply":"2023-06-07T05:41:09.394334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(img_classes))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:11.129577Z","iopub.execute_input":"2023-06-07T05:41:11.130281Z","iopub.status.idle":"2023-06-07T05:41:11.135640Z","shell.execute_reply.started":"2023-06-07T05:41:11.130248Z","shell.execute_reply":"2023-06-07T05:41:11.134538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a dataframe to store the image full pathnames and their corresponding classes\nimport pandas as pd\n\ndataset_df = pd.DataFrame({\n    'image_pathname': img_full_paths,\n    'class': img_classes\n})\n\ndataset_df","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:13.145505Z","iopub.execute_input":"2023-06-07T05:41:13.146467Z","iopub.status.idle":"2023-06-07T05:41:13.171481Z","shell.execute_reply.started":"2023-06-07T05:41:13.146424Z","shell.execute_reply":"2023-06-07T05:41:13.170492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:17.943551Z","iopub.execute_input":"2023-06-07T05:41:17.943913Z","iopub.status.idle":"2023-06-07T05:41:17.960233Z","shell.execute_reply.started":"2023-06-07T05:41:17.943883Z","shell.execute_reply":"2023-06-07T05:41:17.959330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.4 Saving the preprocessed dataset","metadata":{}},{"cell_type":"code","source":"dataset_df.to_csv('../working/faces_dataset_oversampled.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:21.068020Z","iopub.execute_input":"2023-06-07T05:41:21.068547Z","iopub.status.idle":"2023-06-07T05:41:21.254358Z","shell.execute_reply.started":"2023-06-07T05:41:21.068504Z","shell.execute_reply":"2023-06-07T05:41:21.253429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.5 Inspecting an image","metadata":{}},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:24.665564Z","iopub.execute_input":"2023-06-07T05:41:24.666004Z","iopub.status.idle":"2023-06-07T05:41:24.819976Z","shell.execute_reply.started":"2023-06-07T05:41:24.665967Z","shell.execute_reply":"2023-06-07T05:41:24.819063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df.loc[0, 'image_pathname']","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:26.607606Z","iopub.execute_input":"2023-06-07T05:41:26.607987Z","iopub.status.idle":"2023-06-07T05:41:26.615389Z","shell.execute_reply.started":"2023-06-07T05:41:26.607957Z","shell.execute_reply":"2023-06-07T05:41:26.614321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read an image\nimg = cv2.imread(dataset_df.loc[0, 'image_pathname'])\nprint(type(img))\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:28.935702Z","iopub.execute_input":"2023-06-07T05:41:28.936388Z","iopub.status.idle":"2023-06-07T05:41:28.957868Z","shell.execute_reply.started":"2023-06-07T05:41:28.936354Z","shell.execute_reply":"2023-06-07T05:41:28.956957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel BLUE\nimg[:, :, 0]","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:30.861402Z","iopub.execute_input":"2023-06-07T05:41:30.862088Z","iopub.status.idle":"2023-06-07T05:41:30.868513Z","shell.execute_reply.started":"2023-06-07T05:41:30.862055Z","shell.execute_reply":"2023-06-07T05:41:30.867614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel GREEN\nimg[:, :, 1]","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:32.931392Z","iopub.execute_input":"2023-06-07T05:41:32.931744Z","iopub.status.idle":"2023-06-07T05:41:32.938061Z","shell.execute_reply.started":"2023-06-07T05:41:32.931718Z","shell.execute_reply":"2023-06-07T05:41:32.937234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel RED\nimg[:, :, 2]","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:37.133531Z","iopub.execute_input":"2023-06-07T05:41:37.133891Z","iopub.status.idle":"2023-06-07T05:41:37.140792Z","shell.execute_reply.started":"2023-06-07T05:41:37.133862Z","shell.execute_reply":"2023-06-07T05:41:37.139834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.min(), img.max()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:38.921447Z","iopub.execute_input":"2023-06-07T05:41:38.921810Z","iopub.status.idle":"2023-06-07T05:41:38.929035Z","shell.execute_reply.started":"2023-06-07T05:41:38.921767Z","shell.execute_reply":"2023-06-07T05:41:38.928032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:40.911558Z","iopub.execute_input":"2023-06-07T05:41:40.912487Z","iopub.status.idle":"2023-06-07T05:41:41.165136Z","shell.execute_reply.started":"2023-06-07T05:41:40.912444Z","shell.execute_reply":"2023-06-07T05:41:41.164179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#img_RGB = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\nplt.imshow(img_RGB)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:46.349522Z","iopub.execute_input":"2023-06-07T05:41:46.349879Z","iopub.status.idle":"2023-06-07T05:41:46.588906Z","shell.execute_reply.started":"2023-06-07T05:41:46.349851Z","shell.execute_reply":"2023-06-07T05:41:46.588051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(dataset_df.loc[6000, 'image_pathname'])  # BGR\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert BGR to RGB\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:49.955292Z","iopub.execute_input":"2023-06-07T05:41:49.956407Z","iopub.status.idle":"2023-06-07T05:41:50.194949Z","shell.execute_reply.started":"2023-06-07T05:41:49.956366Z","shell.execute_reply":"2023-06-07T05:41:50.194087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:52.805824Z","iopub.execute_input":"2023-06-07T05:41:52.806195Z","iopub.status.idle":"2023-06-07T05:41:52.813192Z","shell.execute_reply.started":"2023-06-07T05:41:52.806145Z","shell.execute_reply":"2023-06-07T05:41:52.812054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.6 Create the training dataset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:54.783220Z","iopub.execute_input":"2023-06-07T05:41:54.783575Z","iopub.status.idle":"2023-06-07T05:41:54.790654Z","shell.execute_reply.started":"2023-06-07T05:41:54.783549Z","shell.execute_reply":"2023-06-07T05:41:54.788384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:41:58.281448Z","iopub.execute_input":"2023-06-07T05:41:58.281818Z","iopub.status.idle":"2023-06-07T05:41:58.288016Z","shell.execute_reply.started":"2023-06-07T05:41:58.281789Z","shell.execute_reply":"2023-06-07T05:41:58.286731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:00.515627Z","iopub.execute_input":"2023-06-07T05:42:00.515981Z","iopub.status.idle":"2023-06-07T05:42:00.529248Z","shell.execute_reply.started":"2023-06-07T05:42:00.515951Z","shell.execute_reply":"2023-06-07T05:42:00.528176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df[\"class\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:03.723578Z","iopub.execute_input":"2023-06-07T05:42:03.723931Z","iopub.status.idle":"2023-06-07T05:42:03.734851Z","shell.execute_reply.started":"2023-06-07T05:42:03.723901Z","shell.execute_reply":"2023-06-07T05:42:03.733754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = sorted(dataset_df[\"class\"].unique())\nn_classes = len(class_names)\n\nprint(f'Number of classes: {n_classes}')\nprint(f'Classes: {class_names}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:07.828379Z","iopub.execute_input":"2023-06-07T05:42:07.828751Z","iopub.status.idle":"2023-06-07T05:42:07.837187Z","shell.execute_reply.started":"2023-06-07T05:42:07.828721Z","shell.execute_reply":"2023-06-07T05:42:07.836211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of samples per class\ndataset_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:10.267306Z","iopub.execute_input":"2023-06-07T05:42:10.268241Z","iopub.status.idle":"2023-06-07T05:42:10.282406Z","shell.execute_reply.started":"2023-06-07T05:42:10.268198Z","shell.execute_reply":"2023-06-07T05:42:10.281542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# for a stratified sampling, we need to pass the labels\nlabels = dataset_df['class']\n\ndataset_df_full_train, dataset_df_test = train_test_split(dataset_df, test_size=0.2, random_state=42, stratify=labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:14.761552Z","iopub.execute_input":"2023-06-07T05:42:14.762001Z","iopub.status.idle":"2023-06-07T05:42:15.179494Z","shell.execute_reply.started":"2023-06-07T05:42:14.761964Z","shell.execute_reply":"2023-06-07T05:42:15.178536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_full_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:21.724831Z","iopub.execute_input":"2023-06-07T05:42:21.725411Z","iopub.status.idle":"2023-06-07T05:42:21.731336Z","shell.execute_reply.started":"2023-06-07T05:42:21.725378Z","shell.execute_reply":"2023-06-07T05:42:21.730362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_full_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:24.727462Z","iopub.execute_input":"2023-06-07T05:42:24.727823Z","iopub.status.idle":"2023-06-07T05:42:24.738260Z","shell.execute_reply.started":"2023-06-07T05:42:24.727794Z","shell.execute_reply":"2023-06-07T05:42:24.737241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:30.956309Z","iopub.execute_input":"2023-06-07T05:42:30.956665Z","iopub.status.idle":"2023-06-07T05:42:30.963084Z","shell.execute_reply.started":"2023-06-07T05:42:30.956638Z","shell.execute_reply":"2023-06-07T05:42:30.962212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for a stratified sampling, we need to pass the labels\nlabels_full_train = dataset_df_full_train['class']\n\ndataset_df_train, dataset_df_val = train_test_split(dataset_df_full_train, train_size=0.8, random_state=42, stratify=labels_full_train)\n\ndataset_df_train['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:33.069504Z","iopub.execute_input":"2023-06-07T05:42:33.070143Z","iopub.status.idle":"2023-06-07T05:42:33.112931Z","shell.execute_reply.started":"2023-06-07T05:42:33.070109Z","shell.execute_reply":"2023-06-07T05:42:33.111946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking class balancing in the validation set\ndataset_df_val['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:36.275284Z","iopub.execute_input":"2023-06-07T05:42:36.275960Z","iopub.status.idle":"2023-06-07T05:42:36.286322Z","shell.execute_reply.started":"2023-06-07T05:42:36.275918Z","shell.execute_reply":"2023-06-07T05:42:36.285333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking class balancing in the training set\ndataset_df_test['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:42:41.033354Z","iopub.execute_input":"2023-06-07T05:42:41.034238Z","iopub.status.idle":"2023-06-07T05:42:41.045994Z","shell.execute_reply.started":"2023-06-07T05:42:41.034191Z","shell.execute_reply":"2023-06-07T05:42:41.045058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.7 Preprocessing the images","metadata":{}},{"cell_type":"code","source":"dataset_df.loc[0, 'image_pathname']","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:44:23.287676Z","iopub.execute_input":"2023-06-07T05:44:23.288059Z","iopub.status.idle":"2023-06-07T05:44:23.294628Z","shell.execute_reply.started":"2023-06-07T05:44:23.288029Z","shell.execute_reply":"2023-06-07T05:44:23.293703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n# BGR\nimg = cv2.imread('../working/oversampled/Adam Sandler/73.jpg')\n# BGR ==> RGB\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:46:00.376207Z","iopub.execute_input":"2023-06-07T05:46:00.376920Z","iopub.status.idle":"2023-06-07T05:46:00.617528Z","shell.execute_reply.started":"2023-06-07T05:46:00.376887Z","shell.execute_reply":"2023-06-07T05:46:00.616634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aspect ratio = width / height\naspect_ratio = img.shape[0] / img.shape[1]\naspect_ratio","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:46:06.283503Z","iopub.execute_input":"2023-06-07T05:46:06.283858Z","iopub.status.idle":"2023-06-07T05:46:06.290627Z","shell.execute_reply.started":"2023-06-07T05:46:06.283830Z","shell.execute_reply":"2023-06-07T05:46:06.289752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# preprocess the image dataset and return the feature matrix and the label array: X, y\ndef preprocess_faces_dataset(dataset_df, label_encoder, verbose=1000):\n#def preprocess_faces_dataset(dataset_df, label_encoder, new_img_dims=(100,100), verbose=1000):\n    image_list = []  # list of preprocessed images (numpy arrays)\n    \n    for index, img_path in enumerate(dataset_df['image_pathname']):\n        img = cv2.imread(img_path)  # BGR\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # RGB\n        \n        # image resizing \n        # for gray or color images, the linear interpolation sounds good\n        #img = cv2.resize(img, new_img_dims, interpolation=cv2.INTER_LINEAR)\n        image_list.append(img)\n        \n        # verbose - print every 1000 iterations\n        if index % verbose == 0:\n            print(f'{index + 1}/{dataset_df.shape[0]} - {img_path}')\n    \n    # feature matrix\n    # shape = (n_imgs, width, height, n_channels)\n    X = np.array(image_list)\n    \n    # feature scaling\n    X = X / 255.0\n    \n    # encoding the classes\n    y = label_encoder.transform(dataset_df['class'])\n    \n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:46:40.797237Z","iopub.execute_input":"2023-06-07T05:46:40.797580Z","iopub.status.idle":"2023-06-07T05:46:40.807202Z","shell.execute_reply.started":"2023-06-07T05:46:40.797553Z","shell.execute_reply":"2023-06-07T05:46:40.806201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training a Label Encoder from the train set\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(dataset_df_train['class'])\n\nlabel_encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:46:50.766035Z","iopub.execute_input":"2023-06-07T05:46:50.766743Z","iopub.status.idle":"2023-06-07T05:46:50.775020Z","shell.execute_reply.started":"2023-06-07T05:46:50.766709Z","shell.execute_reply":"2023-06-07T05:46:50.773972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform/map the string class to the trained numeric class\nlabel_encoder.transform(['Alec Baldwin', 'Claudia Schiffer', 'Zac Efron'])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:46:54.773608Z","iopub.execute_input":"2023-06-07T05:46:54.774604Z","iopub.status.idle":"2023-06-07T05:46:54.781926Z","shell.execute_reply.started":"2023-06-07T05:46:54.774567Z","shell.execute_reply":"2023-06-07T05:46:54.780811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing the train set\nX_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder)\n#X_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder, new_img_dims=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:47:08.359650Z","iopub.execute_input":"2023-06-07T05:47:08.360162Z","iopub.status.idle":"2023-06-07T05:47:14.418064Z","shell.execute_reply.started":"2023-06-07T05:47:08.360119Z","shell.execute_reply":"2023-06-07T05:47:14.417101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'X_train.shape: {X_train.shape}')\nprint(f'y_train (classes): {np.unique(y_train)}')\nprint(f'y_train.shape: {y_train.shape}')\n\n# rescaled 24-bit color image\nprint(f'Min. value of X_train: {X_train.min()}')\nprint(f'Max. value of X_train: {X_train.max()}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:47:16.591635Z","iopub.execute_input":"2023-06-07T05:47:16.592006Z","iopub.status.idle":"2023-06-07T05:47:17.228709Z","shell.execute_reply.started":"2023-06-07T05:47:16.591976Z","shell.execute_reply":"2023-06-07T05:47:17.227488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:47:26.444000Z","iopub.execute_input":"2023-06-07T05:47:26.444704Z","iopub.status.idle":"2023-06-07T05:47:26.683726Z","shell.execute_reply.started":"2023-06-07T05:47:26.444670Z","shell.execute_reply":"2023-06-07T05:47:26.682768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# preprocessing the validation set\nX_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder)\n#X_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder, new_img_dims=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:47:36.853476Z","iopub.execute_input":"2023-06-07T05:47:36.853830Z","iopub.status.idle":"2023-06-07T05:47:38.058223Z","shell.execute_reply.started":"2023-06-07T05:47:36.853801Z","shell.execute_reply":"2023-06-07T05:47:38.057231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'X_val.shape: {X_val.shape}')\nprint(f'y_val (classes): {np.unique(y_val)}')\nprint(f'y_val.shape: {y_val.shape}')\n\n# rescaled 24-bit color image\nprint(f'Min. value of X_val: {X_val.min()}')\nprint(f'Max. value of X_val: {X_val.max()}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:47:40.587560Z","iopub.execute_input":"2023-06-07T05:47:40.588095Z","iopub.status.idle":"2023-06-07T05:47:40.764505Z","shell.execute_reply.started":"2023-06-07T05:47:40.588057Z","shell.execute_reply":"2023-06-07T05:47:40.763652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_val[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:47:44.713232Z","iopub.execute_input":"2023-06-07T05:47:44.714337Z","iopub.status.idle":"2023-06-07T05:47:44.952011Z","shell.execute_reply.started":"2023-06-07T05:47:44.714293Z","shell.execute_reply":"2023-06-07T05:47:44.951134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing the test set\nX_test, y_test = preprocess_faces_dataset(dataset_df_test, label_encoder)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:48:01.023448Z","iopub.execute_input":"2023-06-07T05:48:01.023798Z","iopub.status.idle":"2023-06-07T05:48:02.525290Z","shell.execute_reply.started":"2023-06-07T05:48:01.023770Z","shell.execute_reply":"2023-06-07T05:48:02.524346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_test[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:48:04.477697Z","iopub.execute_input":"2023-06-07T05:48:04.478108Z","iopub.status.idle":"2023-06-07T05:48:04.725125Z","shell.execute_reply.started":"2023-06-07T05:48:04.478076Z","shell.execute_reply":"2023-06-07T05:48:04.724147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.8 Saving the preprocessed data","metadata":{}},{"cell_type":"code","source":"import os\n\nout_dir = '../working/preprocessed'\n\nif not os.path.exists(out_dir):\n    os.makedirs(out_dir)\n    \ndataset_df_full_train.to_csv(os.path.join(out_dir, 'full_train.csv'), index=False)\n\ndataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\nnp.save(os.path.join(out_dir, 'train_data_64x64x3.npy'), X_train)\nnp.save(os.path.join(out_dir, 'train_labels.npy'), y_train)\n\ndataset_df_val.to_csv(os.path.join(out_dir, 'validation.csv'), index=False)\nnp.save(os.path.join(out_dir, 'validation_data_64x64x3.npy'), X_val)\nnp.save(os.path.join(out_dir, 'validation_labels.npy'), y_val)\n\ndataset_df_test.to_csv(os.path.join(out_dir, 'test.csv'), index=False)\nnp.save(os.path.join(out_dir, 'test_data_64x64x3.npy'), X_test)\nnp.save(os.path.join(out_dir, 'test_labels.npy'), y_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:48:17.775547Z","iopub.execute_input":"2023-06-07T05:48:17.775906Z","iopub.status.idle":"2023-06-07T05:48:37.271102Z","shell.execute_reply.started":"2023-06-07T05:48:17.775877Z","shell.execute_reply":"2023-06-07T05:48:37.270108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Training the model","metadata":{}},{"cell_type":"markdown","source":"# 2.1 Stablish base model for transfer learning VGG16","metadata":{}},{"cell_type":"code","source":"# https://keras.io/api/applications/vgg/\n# https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4\n\nfrom tensorflow.keras.applications import VGG16\n\nbase_model = VGG16(include_top=None,   # we will ignore the top layers that consists of the MLP classifier of VGG16\n                   weights=\"imagenet\", # we will use the weights learned for the ImageNet dataset\n                   input_shape=(100, 100, 3))  # let's consider a smaller resolution than the original paper due to lack of memory\n\n\n# freeze the base model weights ==> these weights won't be updated during training\n# i.e., the weights of all layers from the base model are not updated\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:48:48.921356Z","iopub.execute_input":"2023-06-07T05:48:48.921707Z","iopub.status.idle":"2023-06-07T05:48:52.420712Z","shell.execute_reply.started":"2023-06-07T05:48:48.921681Z","shell.execute_reply":"2023-06-07T05:48:52.419609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:48:54.645282Z","iopub.execute_input":"2023-06-07T05:48:54.645635Z","iopub.status.idle":"2023-06-07T05:48:54.689135Z","shell.execute_reply.started":"2023-06-07T05:48:54.645606Z","shell.execute_reply":"2023-06-07T05:48:54.688430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.2 Define the connected model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\n\n\nmodel = Sequential([\n    # our base model - feature extraction\n    base_model,\n    \n    Flatten(),\n    \n    # FC classifier\n    Dense(256, activation='relu'),\n  #  Dense(128, activation='relu'),\n  #  Dense(64, activation='relu'),\n    \n    Dense(83, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:49:23.281484Z","iopub.execute_input":"2023-06-07T05:49:23.282520Z","iopub.status.idle":"2023-06-07T05:49:23.383954Z","shell.execute_reply.started":"2023-06-07T05:49:23.282472Z","shell.execute_reply":"2023-06-07T05:49:23.383092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:49:31.481966Z","iopub.execute_input":"2023-06-07T05:49:31.482348Z","iopub.status.idle":"2023-06-07T05:49:31.504258Z","shell.execute_reply.started":"2023-06-07T05:49:31.482318Z","shell.execute_reply":"2023-06-07T05:49:31.503587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.3 Compile and run the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nopt = Adam(learning_rate=0.001)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:49:45.137047Z","iopub.execute_input":"2023-06-07T05:49:45.137721Z","iopub.status.idle":"2023-06-07T05:49:45.159050Z","shell.execute_reply.started":"2023-06-07T05:49:45.137688Z","shell.execute_reply":"2023-06-07T05:49:45.158191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nearly_stopping_cb = tensorflow.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:49:54.465294Z","iopub.execute_input":"2023-06-07T05:49:54.465665Z","iopub.status.idle":"2023-06-07T05:49:54.470712Z","shell.execute_reply.started":"2023-06-07T05:49:54.465634Z","shell.execute_reply":"2023-06-07T05:49:54.469805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2023-06-07T05:50:11.717483Z","iopub.execute_input":"2023-06-07T05:50:11.718371Z","iopub.status.idle":"2023-06-07T05:54:18.600094Z","shell.execute_reply.started":"2023-06-07T05:50:11.718328Z","shell.execute_reply":"2023-06-07T05:54:18.599068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.4 Visualizing the training history","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nhistory_df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:01:14.025485Z","iopub.execute_input":"2023-06-07T06:01:14.025847Z","iopub.status.idle":"2023-06-07T06:01:14.031618Z","shell.execute_reply.started":"2023-06-07T06:01:14.025818Z","shell.execute_reply":"2023-06-07T06:01:14.030685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\nplt.grid(True)\nplt.xlabel('Epochs')\nplt.ylabel('Score')\n\nhistory_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\nplt.grid(True)\nplt.xlabel('Epochs')\nplt.ylabel('Score')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:01:16.353916Z","iopub.execute_input":"2023-06-07T06:01:16.354639Z","iopub.status.idle":"2023-06-07T06:01:41.540738Z","shell.execute_reply.started":"2023-06-07T06:01:16.354603Z","shell.execute_reply":"2023-06-07T06:01:41.539716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:01:45.745485Z","iopub.execute_input":"2023-06-07T06:01:45.745845Z","iopub.status.idle":"2023-06-07T06:01:53.135889Z","shell.execute_reply.started":"2023-06-07T06:01:45.745817Z","shell.execute_reply":"2023-06-07T06:01:53.134201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_proba = model.predict(X_test)\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:01:56.133822Z","iopub.execute_input":"2023-06-07T06:01:56.134201Z","iopub.status.idle":"2023-06-07T06:02:03.570875Z","shell.execute_reply.started":"2023-06-07T06:01:56.134151Z","shell.execute_reply":"2023-06-07T06:02:03.569573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = np.argmax(y_test_proba, axis=1)\ny_test_pred","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:02:05.458383Z","iopub.execute_input":"2023-06-07T06:02:05.458742Z","iopub.status.idle":"2023-06-07T06:02:05.466717Z","shell.execute_reply.started":"2023-06-07T06:02:05.458713Z","shell.execute_reply":"2023-06-07T06:02:05.465564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nclass_names = label_encoder.classes_\n\nprint(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:02:07.960039Z","iopub.execute_input":"2023-06-07T06:02:07.960722Z","iopub.status.idle":"2023-06-07T06:02:07.994589Z","shell.execute_reply.started":"2023-06-07T06:02:07.960689Z","shell.execute_reply":"2023-06-07T06:02:07.993686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_class_name = label_encoder.inverse_transform(y_test)\ny_test_pred_class_name = label_encoder.inverse_transform(y_test_pred)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:02:14.596043Z","iopub.execute_input":"2023-06-07T06:02:14.596739Z","iopub.status.idle":"2023-06-07T06:02:14.602641Z","shell.execute_reply.started":"2023-06-07T06:02:14.596705Z","shell.execute_reply":"2023-06-07T06:02:14.601602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"misclassification_mask = y_test_class_name != y_test_pred_class_name","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:02:23.865604Z","iopub.execute_input":"2023-06-07T06:02:23.865974Z","iopub.status.idle":"2023-06-07T06:02:23.871473Z","shell.execute_reply.started":"2023-06-07T06:02:23.865944Z","shell.execute_reply":"2023-06-07T06:02:23.870546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sheep_error_mask = misclassification_mask & (y_test_class_name == \"Alec Baldwin\")\n\nnp.argwhere(sheep_error_mask)[:3]","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:02:25.335824Z","iopub.execute_input":"2023-06-07T06:02:25.336727Z","iopub.status.idle":"2023-06-07T06:02:25.345092Z","shell.execute_reply.started":"2023-06-07T06:02:25.336693Z","shell.execute_reply":"2023-06-07T06:02:25.344094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_idx = 18\n\nplt.imshow(X_test[img_idx])\nplt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T06:02:28.634101Z","iopub.execute_input":"2023-06-07T06:02:28.634473Z","iopub.status.idle":"2023-06-07T06:02:29.005943Z","shell.execute_reply.started":"2023-06-07T06:02:28.634445Z","shell.execute_reply":"2023-06-07T06:02:29.005073Z"},"trusted":true},"execution_count":null,"outputs":[]}]}