{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-02T04:00:44.473005Z","iopub.execute_input":"2023-06-02T04:00:44.473747Z","iopub.status.idle":"2023-06-02T04:00:52.920009Z","shell.execute_reply.started":"2023-06-02T04:00:44.473711Z","shell.execute_reply":"2023-06-02T04:00:52.919096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1. Dataset**","metadata":{}},{"cell_type":"markdown","source":"# 1.1 Profiling","metadata":{}},{"cell_type":"code","source":"ls ../input/ifsp-d3apl-2023-face-recognition/train/train/","metadata":{"execution":{"iopub.status.busy":"2023-06-02T04:01:29.236301Z","iopub.execute_input":"2023-06-02T04:01:29.236669Z","iopub.status.idle":"2023-06-02T04:01:29.555730Z","shell.execute_reply.started":"2023-06-02T04:01:29.236643Z","shell.execute_reply":"2023-06-02T04:01:29.554743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndataset_folder = '../input/ifsp-d3apl-2023-face-recognition/train/train/'\n\nclass_folders = sorted(os.listdir(dataset_folder))\n\n\nprint(class_folders)\nprint(f'Number of class: {len(class_folders)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T04:01:33.109372Z","iopub.execute_input":"2023-06-02T04:01:33.109759Z","iopub.status.idle":"2023-06-02T04:01:33.116695Z","shell.execute_reply.started":"2023-06-02T04:01:33.109730Z","shell.execute_reply":"2023-06-02T04:01:33.115525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show me the class proportions: number of samples per class\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    \n    class_img_filenames = os.listdir(full_class_folder)\n    print(f'Number of Images for Class \"{class_folder}\": {len(class_img_filenames)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T04:01:35.661001Z","iopub.execute_input":"2023-06-02T04:01:35.661350Z","iopub.status.idle":"2023-06-02T04:01:35.721472Z","shell.execute_reply.started":"2023-06-02T04:01:35.661317Z","shell.execute_reply":"2023-06-02T04:01:35.720592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\n# List of directories\n#directories = ['dir1', 'dir2', 'dir3']\n\n# Dictionary to store directory and file count\nfile_counts = {}\n\n# Count files in each directory\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    file_counts[class_folder] = len(glob.glob(os.path.join(full_class_folder, '*')))\n\n# Sort file counts by value in descending order\nsorted_counts = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)\n\nprint(sorted_counts)\n\n# Print the sorted file counts\n#for class_folder, count in sorted_counts:\n#    print(f\"{class_folder}: {count} files\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T04:35:11.019490Z","iopub.execute_input":"2023-06-02T04:35:11.019891Z","iopub.status.idle":"2023-06-02T04:35:11.137833Z","shell.execute_reply.started":"2023-06-02T04:35:11.019862Z","shell.execute_reply":"2023-06-02T04:35:11.136569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.utils import img_to_array\nimport os\n\n# Set the paths for the original and oversampled image folders\noriginal_folder = dataset_folder\noversampled_folder = '../working/oversampled'\n\n\n# Create the oversampled folder if it doesn't exist\nos.makedirs(oversampled_folder, exist_ok=True)\n\n# Create an instance of the ImageDataGenerator\ndatagen = ImageDataGenerator(\n    rescale=1./255,  # Normalize pixel values to [0, 1]\n    rotation_range=20,  # Randomly rotate images within the range of 20 degrees\n    width_shift_range=0.1,  # Randomly shift the width of images by 10%\n    height_shift_range=0.1,  # Randomly shift the height of images by 10%\n    shear_range=0.2,  # Apply random shear transformations\n    zoom_range=0.2,  # Apply random zoom transformations\n    horizontal_flip=True,  # Randomly flip images horizontally\n    fill_mode='nearest'  # Fill any newly created pixels after rotation or shifting\n)\n\n# show me the class proportions: number of samples per class\n\nfor class_folder in class_folders:\n    \n    for class_img_filename in class_img_filenames:\n        \n        img_path = os.path.join(original_folder,class_folder,class_img_filename)\n        \n        # Load the image\n        img = load_img(img_path)\n        \n        # Expand dimensions to match the batch size\n        img = img_to_array(img)\n        img = img.reshape((1,) + img.shape)\n        \n        # Generate augmented images and save them to the oversampled folder\n        save_prefix = os.path.splitext(filename)[0]  # Get the filename without extension\n        save_path = os.path.join(oversampled_folder, class_folder, save_prefix)\n        \n        # Generate oversampled images\n        i = 0\n        for batch in datagen.flow(img, batch_size=1, save_to_dir=oversampled_folder, save_prefix=save_prefix, save_format='jpg'):\n            i += 1\n            if i >= 5:# Generate 5 oversampled images for each original image\n                break\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:08:22.181694Z","iopub.execute_input":"2023-06-02T05:08:22.182060Z","iopub.status.idle":"2023-06-02T05:08:22.238194Z","shell.execute_reply.started":"2023-06-02T05:08:22.182031Z","shell.execute_reply":"2023-06-02T05:08:22.236618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.2 Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"max_n_samples_per_class = 80","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.263676Z","iopub.execute_input":"2023-05-29T18:21:41.264182Z","iopub.status.idle":"2023-05-29T18:21:41.268743Z","shell.execute_reply.started":"2023-05-29T18:21:41.264151Z","shell.execute_reply":"2023-05-29T18:21:41.267682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\ndataset_folder = '../input/ifsp-d3apl-2023-face-recognition/train/train/'\nclass_folders = sorted(os.listdir(dataset_folder))\n\n# OPTIONAL: just to get the same selected images\nrandom.seed(42)\n\nimg_full_paths = []\nimg_classes = []\n\nfor class_folder in class_folders:\n    img_class = class_folder  # english\n    print(f'Class: {img_class}')  # italiano\n    \n    # translated class\n    #img_class = translate[class_folder]  # english\n    #print(f'Translation: {img_class}')  # italiano\n    \n    # get the full class folder pathname\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    print(full_class_folder)\n    \n    # get all image filenames (without their parent dir) for the current class/animal\n    class_img_filenames = sorted(os.listdir(full_class_folder))\n    print(len(class_img_filenames))\n    \n    #### undersampling from scratch\n    ### one possible strategy to select `max_n_samples_per_class` of samples randomly\n    # random.shuffle(class_img_filenames)\n    # class_img_filenames = class_img_filenames[:max_n_samples_per_class]\n\n    class_img_filenames = random.sample(class_img_filenames, max_n_samples_per_class)\n    print(f'Number of images: {len(class_img_filenames)}')\n    \n    for img_filename in class_img_filenames:\n        full_img_path = os.path.join(full_class_folder, img_filename)\n        \n        img_full_paths.append(full_img_path)\n        img_classes.append(img_class)\n    \n    print()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.270035Z","iopub.execute_input":"2023-05-29T18:21:41.271092Z","iopub.status.idle":"2023-05-29T18:21:41.359145Z","shell.execute_reply.started":"2023-05-29T18:21:41.27106Z","shell.execute_reply":"2023-05-29T18:21:41.358199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(img_full_paths))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.360549Z","iopub.execute_input":"2023-05-29T18:21:41.361122Z","iopub.status.idle":"2023-05-29T18:21:41.366622Z","shell.execute_reply.started":"2023-05-29T18:21:41.361094Z","shell.execute_reply":"2023-05-29T18:21:41.365436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(img_classes))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.368343Z","iopub.execute_input":"2023-05-29T18:21:41.368978Z","iopub.status.idle":"2023-05-29T18:21:41.383181Z","shell.execute_reply.started":"2023-05-29T18:21:41.368946Z","shell.execute_reply":"2023-05-29T18:21:41.382113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a dataframe to store the image full pathnames and their corresponding classes\nimport pandas as pd\n\ndataset_df = pd.DataFrame({\n    'image_pathname': img_full_paths,\n    'class': img_classes\n})\n\ndataset_df","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.384269Z","iopub.execute_input":"2023-05-29T18:21:41.384574Z","iopub.status.idle":"2023-05-29T18:21:41.439797Z","shell.execute_reply.started":"2023-05-29T18:21:41.384553Z","shell.execute_reply":"2023-05-29T18:21:41.438832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.444625Z","iopub.execute_input":"2023-05-29T18:21:41.445235Z","iopub.status.idle":"2023-05-29T18:21:41.461076Z","shell.execute_reply.started":"2023-05-29T18:21:41.445204Z","shell.execute_reply":"2023-05-29T18:21:41.460232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.3 Saving the preprocessed dataset","metadata":{}},{"cell_type":"code","source":"dataset_df.to_csv('../working/faces_dataset_balanced.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.462232Z","iopub.execute_input":"2023-05-29T18:21:41.463194Z","iopub.status.idle":"2023-05-29T18:21:41.517768Z","shell.execute_reply.started":"2023-05-29T18:21:41.463162Z","shell.execute_reply":"2023-05-29T18:21:41.51582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.4 Inspect an image","metadata":{}},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.521186Z","iopub.execute_input":"2023-05-29T18:21:41.521693Z","iopub.status.idle":"2023-05-29T18:21:41.74214Z","shell.execute_reply.started":"2023-05-29T18:21:41.521652Z","shell.execute_reply":"2023-05-29T18:21:41.741284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df.loc[0, 'image_pathname']","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.743521Z","iopub.execute_input":"2023-05-29T18:21:41.74411Z","iopub.status.idle":"2023-05-29T18:21:41.751279Z","shell.execute_reply.started":"2023-05-29T18:21:41.74403Z","shell.execute_reply":"2023-05-29T18:21:41.750277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read an image\nimg = cv2.imread(dataset_df.loc[0, 'image_pathname'])\nprint(type(img))\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.752888Z","iopub.execute_input":"2023-05-29T18:21:41.753271Z","iopub.status.idle":"2023-05-29T18:21:41.786774Z","shell.execute_reply.started":"2023-05-29T18:21:41.753239Z","shell.execute_reply":"2023-05-29T18:21:41.785265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel BLUE\nimg[:, :, 0]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.788374Z","iopub.execute_input":"2023-05-29T18:21:41.789115Z","iopub.status.idle":"2023-05-29T18:21:41.798618Z","shell.execute_reply.started":"2023-05-29T18:21:41.789079Z","shell.execute_reply":"2023-05-29T18:21:41.797109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel GREEN\nimg[:, :, 1]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.800964Z","iopub.execute_input":"2023-05-29T18:21:41.801371Z","iopub.status.idle":"2023-05-29T18:21:41.815622Z","shell.execute_reply.started":"2023-05-29T18:21:41.80132Z","shell.execute_reply":"2023-05-29T18:21:41.813251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel RED\nimg[:, :, 2]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.817864Z","iopub.execute_input":"2023-05-29T18:21:41.818287Z","iopub.status.idle":"2023-05-29T18:21:41.833757Z","shell.execute_reply.started":"2023-05-29T18:21:41.818252Z","shell.execute_reply":"2023-05-29T18:21:41.832306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.min(), img.max()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.835337Z","iopub.execute_input":"2023-05-29T18:21:41.835681Z","iopub.status.idle":"2023-05-29T18:21:41.851109Z","shell.execute_reply.started":"2023-05-29T18:21:41.835652Z","shell.execute_reply":"2023-05-29T18:21:41.849171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:41.852779Z","iopub.execute_input":"2023-05-29T18:21:41.853121Z","iopub.status.idle":"2023-05-29T18:21:42.064862Z","shell.execute_reply.started":"2023-05-29T18:21:41.853097Z","shell.execute_reply":"2023-05-29T18:21:42.063722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#img_RGB = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:42.066108Z","iopub.execute_input":"2023-05-29T18:21:42.06699Z","iopub.status.idle":"2023-05-29T18:21:42.273724Z","shell.execute_reply.started":"2023-05-29T18:21:42.066957Z","shell.execute_reply":"2023-05-29T18:21:42.27284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the color image as a gray image\ngray_img = cv2.imread(dataset_df.loc[0, 'image_pathname'], cv2.IMREAD_GRAYSCALE)\n\nprint(gray_img.shape)\n\nplt.imshow(gray_img, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:42.275075Z","iopub.execute_input":"2023-05-29T18:21:42.275621Z","iopub.status.idle":"2023-05-29T18:21:42.468016Z","shell.execute_reply.started":"2023-05-29T18:21:42.275592Z","shell.execute_reply":"2023-05-29T18:21:42.466649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(dataset_df.loc[6000, 'image_pathname'])  # BGR\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert BGR to RGB\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:42.469532Z","iopub.execute_input":"2023-05-29T18:21:42.470142Z","iopub.status.idle":"2023-05-29T18:21:42.662761Z","shell.execute_reply.started":"2023-05-29T18:21:42.470106Z","shell.execute_reply":"2023-05-29T18:21:42.661795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:42.663948Z","iopub.execute_input":"2023-05-29T18:21:42.664271Z","iopub.status.idle":"2023-05-29T18:21:42.670713Z","shell.execute_reply.started":"2023-05-29T18:21:42.664243Z","shell.execute_reply":"2023-05-29T18:21:42.669476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.4 Create the training dataset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:42.671933Z","iopub.execute_input":"2023-05-29T18:21:42.672213Z","iopub.status.idle":"2023-05-29T18:21:53.514705Z","shell.execute_reply.started":"2023-05-29T18:21:42.672191Z","shell.execute_reply":"2023-05-29T18:21:53.512795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:53.516731Z","iopub.execute_input":"2023-05-29T18:21:53.517666Z","iopub.status.idle":"2023-05-29T18:21:53.532829Z","shell.execute_reply.started":"2023-05-29T18:21:53.517632Z","shell.execute_reply":"2023-05-29T18:21:53.53141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:53.534599Z","iopub.execute_input":"2023-05-29T18:21:53.536074Z","iopub.status.idle":"2023-05-29T18:21:53.559706Z","shell.execute_reply.started":"2023-05-29T18:21:53.53603Z","shell.execute_reply":"2023-05-29T18:21:53.55801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df[\"class\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:53.560875Z","iopub.execute_input":"2023-05-29T18:21:53.56194Z","iopub.status.idle":"2023-05-29T18:21:53.578715Z","shell.execute_reply.started":"2023-05-29T18:21:53.561891Z","shell.execute_reply":"2023-05-29T18:21:53.577575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = sorted(dataset_df[\"class\"].unique())\nn_classes = len(class_names)\n\nprint(f'Number of classes: {n_classes}')\nprint(f'Classes: {class_names}')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:53.583379Z","iopub.execute_input":"2023-05-29T18:21:53.583881Z","iopub.status.idle":"2023-05-29T18:21:53.593856Z","shell.execute_reply.started":"2023-05-29T18:21:53.583853Z","shell.execute_reply":"2023-05-29T18:21:53.592066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of samples per class\ndataset_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:53.595163Z","iopub.execute_input":"2023-05-29T18:21:53.596331Z","iopub.status.idle":"2023-05-29T18:21:53.610198Z","shell.execute_reply.started":"2023-05-29T18:21:53.596278Z","shell.execute_reply":"2023-05-29T18:21:53.608921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# for a stratified sampling, we need to pass the labels\nlabels = dataset_df['class']\n\ndataset_df_full_train, dataset_df_test = train_test_split(dataset_df, test_size=0.2, random_state=42, stratify=labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:53.611863Z","iopub.execute_input":"2023-05-29T18:21:53.612338Z","iopub.status.idle":"2023-05-29T18:21:54.075187Z","shell.execute_reply.started":"2023-05-29T18:21:53.612312Z","shell.execute_reply":"2023-05-29T18:21:54.073673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_full_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:54.076899Z","iopub.execute_input":"2023-05-29T18:21:54.077291Z","iopub.status.idle":"2023-05-29T18:21:54.084841Z","shell.execute_reply.started":"2023-05-29T18:21:54.077259Z","shell.execute_reply":"2023-05-29T18:21:54.083503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_full_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:54.086182Z","iopub.execute_input":"2023-05-29T18:21:54.086505Z","iopub.status.idle":"2023-05-29T18:21:54.103466Z","shell.execute_reply.started":"2023-05-29T18:21:54.086479Z","shell.execute_reply":"2023-05-29T18:21:54.102128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:54.104779Z","iopub.execute_input":"2023-05-29T18:21:54.105128Z","iopub.status.idle":"2023-05-29T18:21:54.120015Z","shell.execute_reply.started":"2023-05-29T18:21:54.105098Z","shell.execute_reply":"2023-05-29T18:21:54.118687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for a stratified sampling, we need to pass the labels\nlabels_full_train = dataset_df_full_train['class']\n\ndataset_df_train, dataset_df_val = train_test_split(dataset_df_full_train, train_size=0.8, random_state=42, stratify=labels_full_train)\n\ndataset_df_train['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:54.121019Z","iopub.execute_input":"2023-05-29T18:21:54.122221Z","iopub.status.idle":"2023-05-29T18:21:54.145877Z","shell.execute_reply.started":"2023-05-29T18:21:54.122168Z","shell.execute_reply":"2023-05-29T18:21:54.143138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking class balancing in the validation set\ndataset_df_val['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:54.14808Z","iopub.execute_input":"2023-05-29T18:21:54.14854Z","iopub.status.idle":"2023-05-29T18:21:54.159946Z","shell.execute_reply.started":"2023-05-29T18:21:54.148507Z","shell.execute_reply":"2023-05-29T18:21:54.158146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking class balancing in the training set\ndataset_df_test['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T18:21:54.161888Z","iopub.execute_input":"2023-05-29T18:21:54.162268Z","iopub.status.idle":"2023-05-29T18:21:54.179595Z","shell.execute_reply.started":"2023-05-29T18:21:54.162236Z","shell.execute_reply":"2023-05-29T18:21:54.178458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2. Training the model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n\n\ndef build_cnn(input_shape=(64, 64, 3), n_classes=83):\n    model = Sequential([\n        # feature extraction\n        Conv2D(filters=32, kernel_size=(4,4), activation='relu', input_shape=input_shape),\n        MaxPool2D(pool_size=(2,2)),\n        Conv2D(filters=32, kernel_size=(4,4), activation='relu'),\n        MaxPool2D(pool_size=(2,2)),\n        Flatten(),\n        \n        # Fully-Connected Neural Network ==> MLP\n        Dense(256, activation='relu'),\n        Dense(n_classes, activation='softmax')\n    ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:02.37988Z","iopub.execute_input":"2023-05-29T20:04:02.380302Z","iopub.status.idle":"2023-05-29T20:04:02.388345Z","shell.execute_reply.started":"2023-05-29T20:04:02.38027Z","shell.execute_reply":"2023-05-29T20:04:02.387038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninput_shape = (64, 64, 3)\n\nmodel = build_cnn(input_shape, n_classes)\nopt = tf.keras.optimizers.SGD(learning_rate=0.01)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:06.608701Z","iopub.execute_input":"2023-05-29T20:04:06.609039Z","iopub.status.idle":"2023-05-29T20:04:06.688178Z","shell.execute_reply.started":"2023-05-29T20:04:06.609016Z","shell.execute_reply":"2023-05-29T20:04:06.687156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:10.019658Z","iopub.execute_input":"2023-05-29T20:04:10.020034Z","iopub.status.idle":"2023-05-29T20:04:10.046016Z","shell.execute_reply.started":"2023-05-29T20:04:10.020009Z","shell.execute_reply":"2023-05-29T20:04:10.044645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n# vertical\nplot_model(model, show_shapes=True, show_layer_activations=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:13.794458Z","iopub.execute_input":"2023-05-29T20:04:13.794862Z","iopub.status.idle":"2023-05-29T20:04:13.88854Z","shell.execute_reply.started":"2023-05-29T20:04:13.79483Z","shell.execute_reply":"2023-05-29T20:04:13.885614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.1 Preprocessing the images","metadata":{}},{"cell_type":"code","source":"dataset_df.loc[0, 'image_pathname']","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:18.006259Z","iopub.execute_input":"2023-05-29T20:04:18.006633Z","iopub.status.idle":"2023-05-29T20:04:18.01389Z","shell.execute_reply.started":"2023-05-29T20:04:18.006604Z","shell.execute_reply":"2023-05-29T20:04:18.012428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n# BGR\nimg = cv2.imread('../input/ifsp-d3apl-2023-face-recognition/train/train/Adam Sandler/73.jpg')\n# BGR ==> RGB\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:20.070007Z","iopub.execute_input":"2023-05-29T20:04:20.070416Z","iopub.status.idle":"2023-05-29T20:04:20.281654Z","shell.execute_reply.started":"2023-05-29T20:04:20.070379Z","shell.execute_reply":"2023-05-29T20:04:20.280428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aspect ratio = width / height\naspect_ratio = img.shape[0] / img.shape[1]\naspect_ratio","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:22.708245Z","iopub.execute_input":"2023-05-29T20:04:22.708666Z","iopub.status.idle":"2023-05-29T20:04:22.716267Z","shell.execute_reply.started":"2023-05-29T20:04:22.708633Z","shell.execute_reply":"2023-05-29T20:04:22.714552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_img_dims = (64, 64)\n\n# resizing\nres_img = cv2.resize(img, new_img_dims, interpolation=cv2.INTER_LINEAR)\n\nplt.imshow(res_img)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:31.663878Z","iopub.execute_input":"2023-05-29T20:04:31.664286Z","iopub.status.idle":"2023-05-29T20:04:31.884063Z","shell.execute_reply.started":"2023-05-29T20:04:31.664253Z","shell.execute_reply":"2023-05-29T20:04:31.882717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### aspect ratio = width / height\naspect_ratio = img.shape[0] / img.shape[1]\naspect_ratio\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:34.569266Z","iopub.execute_input":"2023-05-29T20:04:34.569642Z","iopub.status.idle":"2023-05-29T20:04:34.575655Z","shell.execute_reply.started":"2023-05-29T20:04:34.569618Z","shell.execute_reply":"2023-05-29T20:04:34.574739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# preprocess the image dataset and return the feature matrix and the label array: X, y\ndef preprocess_faces_dataset(dataset_df, label_encoder, new_img_dims=(64,64), verbose=1000):\n#def preprocess_faces_dataset(dataset_df, label_encoder, new_img_dims=(100,100), verbose=1000):\n    image_list = []  # list of preprocessed images (numpy arrays)\n    \n    for index, img_path in enumerate(dataset_df['image_pathname']):\n        img = cv2.imread(img_path)  # BGR\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # RGB\n        \n        # image resizing \n        # for gray or color images, the linear interpolation sounds good\n        img = cv2.resize(img, new_img_dims, interpolation=cv2.INTER_LINEAR)\n        image_list.append(img)\n        \n        # verbose - print every 1000 iterations\n        if index % verbose == 0:\n            print(f'{index + 1}/{dataset_df.shape[0]} - {img_path}')\n    \n    # feature matrix\n    # shape = (n_imgs, width, height, n_channels)\n    X = np.array(image_list)\n    \n    # feature scaling\n    X = X / 255.0\n    \n    # encoding the classes\n    y = label_encoder.transform(dataset_df['class'])\n    \n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:43.414662Z","iopub.execute_input":"2023-05-29T20:04:43.415004Z","iopub.status.idle":"2023-05-29T20:04:43.42371Z","shell.execute_reply.started":"2023-05-29T20:04:43.414982Z","shell.execute_reply":"2023-05-29T20:04:43.422114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training a Label Encoder from the train set\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(dataset_df_train['class'])\n\nlabel_encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:46.803435Z","iopub.execute_input":"2023-05-29T20:04:46.803803Z","iopub.status.idle":"2023-05-29T20:04:46.813928Z","shell.execute_reply.started":"2023-05-29T20:04:46.803773Z","shell.execute_reply":"2023-05-29T20:04:46.812139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform/map the string class to the trained numeric class\nlabel_encoder.transform(['Alec Baldwin', 'Claudia Schiffer', 'Zac Efron'])","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:51.617143Z","iopub.execute_input":"2023-05-29T20:04:51.617532Z","iopub.status.idle":"2023-05-29T20:04:51.626277Z","shell.execute_reply.started":"2023-05-29T20:04:51.617502Z","shell.execute_reply":"2023-05-29T20:04:51.624511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing the train set\nX_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder, new_img_dims=(64, 64))\n#X_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder, new_img_dims=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:04:56.778026Z","iopub.execute_input":"2023-05-29T20:04:56.778386Z","iopub.status.idle":"2023-05-29T20:05:09.505049Z","shell.execute_reply.started":"2023-05-29T20:04:56.77834Z","shell.execute_reply":"2023-05-29T20:05:09.503846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'X_train.shape: {X_train.shape}')\nprint(f'y_train (classes): {np.unique(y_train)}')\nprint(f'y_train.shape: {y_train.shape}')\n\n# rescaled 24-bit color image\nprint(f'Min. value of X_train: {X_train.min()}')\nprint(f'Max. value of X_train: {X_train.max()}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:05:20.180849Z","iopub.execute_input":"2023-05-29T20:05:20.181344Z","iopub.status.idle":"2023-05-29T20:05:20.252749Z","shell.execute_reply.started":"2023-05-29T20:05:20.18131Z","shell.execute_reply":"2023-05-29T20:05:20.251289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:05:23.785502Z","iopub.execute_input":"2023-05-29T20:05:23.785907Z","iopub.status.idle":"2023-05-29T20:05:24.024396Z","shell.execute_reply.started":"2023-05-29T20:05:23.785882Z","shell.execute_reply":"2023-05-29T20:05:24.023002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# preprocessing the validation set\nX_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder, new_img_dims=(64, 64))\n#X_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder, new_img_dims=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:05:30.294464Z","iopub.execute_input":"2023-05-29T20:05:30.296535Z","iopub.status.idle":"2023-05-29T20:05:37.624582Z","shell.execute_reply.started":"2023-05-29T20:05:30.296493Z","shell.execute_reply":"2023-05-29T20:05:37.623179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'X_val.shape: {X_val.shape}')\nprint(f'y_val (classes): {np.unique(y_val)}')\nprint(f'y_val.shape: {y_val.shape}')\n\n# rescaled 24-bit color image\nprint(f'Min. value of X_val: {X_val.min()}')\nprint(f'Max. value of X_val: {X_val.max()}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:05:40.657815Z","iopub.execute_input":"2023-05-29T20:05:40.658197Z","iopub.status.idle":"2023-05-29T20:05:40.684243Z","shell.execute_reply.started":"2023-05-29T20:05:40.658167Z","shell.execute_reply":"2023-05-29T20:05:40.682371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_val[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:05:42.774308Z","iopub.execute_input":"2023-05-29T20:05:42.774704Z","iopub.status.idle":"2023-05-29T20:05:43.018315Z","shell.execute_reply.started":"2023-05-29T20:05:42.774675Z","shell.execute_reply":"2023-05-29T20:05:43.016459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing the test set\nX_test, y_test = preprocess_faces_dataset(dataset_df_test, label_encoder, new_img_dims=(64, 64))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:05:52.595247Z","iopub.execute_input":"2023-05-29T20:05:52.595658Z","iopub.status.idle":"2023-05-29T20:06:01.281754Z","shell.execute_reply.started":"2023-05-29T20:05:52.595633Z","shell.execute_reply":"2023-05-29T20:06:01.279973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_test[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:06:03.518629Z","iopub.execute_input":"2023-05-29T20:06:03.519039Z","iopub.status.idle":"2023-05-29T20:06:03.717653Z","shell.execute_reply.started":"2023-05-29T20:06:03.519011Z","shell.execute_reply":"2023-05-29T20:06:03.715215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.3. Saving the preprocessed data","metadata":{}},{"cell_type":"code","source":"import os\n\nout_dir = '../working/preprocessed'\n\nif not os.path.exists(out_dir):\n    os.makedirs(out_dir)\n    \ndataset_df_full_train.to_csv(os.path.join(out_dir, 'full_train.csv'), index=False)\n\ndataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\nnp.save(os.path.join(out_dir, 'train_data_64x64x3.npy'), X_train)\nnp.save(os.path.join(out_dir, 'train_labels.npy'), y_train)\n\ndataset_df_val.to_csv(os.path.join(out_dir, 'validation.csv'), index=False)\nnp.save(os.path.join(out_dir, 'validation_data_64x64x3.npy'), X_val)\nnp.save(os.path.join(out_dir, 'validation_labels.npy'), y_val)\n\ndataset_df_test.to_csv(os.path.join(out_dir, 'test.csv'), index=False)\nnp.save(os.path.join(out_dir, 'test_data_64x64x3.npy'), X_test)\nnp.save(os.path.join(out_dir, 'test_labels.npy'), y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:06:08.744549Z","iopub.execute_input":"2023-05-29T20:06:08.744992Z","iopub.status.idle":"2023-05-29T20:06:09.934436Z","shell.execute_reply.started":"2023-05-29T20:06:08.744954Z","shell.execute_reply":"2023-05-29T20:06:09.932714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.5 Training the model","metadata":{}},{"cell_type":"code","source":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:06:13.525907Z","iopub.execute_input":"2023-05-29T20:06:13.526346Z","iopub.status.idle":"2023-05-29T20:06:13.533017Z","shell.execute_reply.started":"2023-05-29T20:06:13.526315Z","shell.execute_reply":"2023-05-29T20:06:13.531746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:06:16.376185Z","iopub.execute_input":"2023-05-29T20:06:16.376629Z","iopub.status.idle":"2023-05-29T20:12:26.179067Z","shell.execute_reply.started":"2023-05-29T20:06:16.376594Z","shell.execute_reply":"2023-05-29T20:12:26.1771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nhistory_df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:12:48.628331Z","iopub.execute_input":"2023-05-29T20:12:48.628706Z","iopub.status.idle":"2023-05-29T20:12:48.636891Z","shell.execute_reply.started":"2023-05-29T20:12:48.628683Z","shell.execute_reply":"2023-05-29T20:12:48.63557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\nplt.grid(True)\nplt.xlabel('Epochs')\nplt.ylabel('Score')\n\nhistory_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\nplt.grid(True)\nplt.xlabel('Epochs')\nplt.ylabel('Score')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:12:53.233025Z","iopub.execute_input":"2023-05-29T20:12:53.233471Z","iopub.status.idle":"2023-05-29T20:12:53.708728Z","shell.execute_reply.started":"2023-05-29T20:12:53.23344Z","shell.execute_reply":"2023-05-29T20:12:53.707244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:01.675787Z","iopub.execute_input":"2023-05-29T20:13:01.676189Z","iopub.status.idle":"2023-05-29T20:13:02.708014Z","shell.execute_reply.started":"2023-05-29T20:13:01.676148Z","shell.execute_reply":"2023-05-29T20:13:02.706256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_proba = model.predict(X_test)\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:07.404411Z","iopub.execute_input":"2023-05-29T20:13:07.404867Z","iopub.status.idle":"2023-05-29T20:13:08.470427Z","shell.execute_reply.started":"2023-05-29T20:13:07.404832Z","shell.execute_reply":"2023-05-29T20:13:08.468862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = np.argmax(y_test_proba, axis=1)\ny_test_pred","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:10.966064Z","iopub.execute_input":"2023-05-29T20:13:10.966508Z","iopub.status.idle":"2023-05-29T20:13:10.977512Z","shell.execute_reply.started":"2023-05-29T20:13:10.966476Z","shell.execute_reply":"2023-05-29T20:13:10.975747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nclass_names = label_encoder.classes_\n\nprint(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:14.004992Z","iopub.execute_input":"2023-05-29T20:13:14.005407Z","iopub.status.idle":"2023-05-29T20:13:14.025305Z","shell.execute_reply.started":"2023-05-29T20:13:14.005376Z","shell.execute_reply":"2023-05-29T20:13:14.023235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_class_name = label_encoder.inverse_transform(y_test)\ny_test_pred_class_name = label_encoder.inverse_transform(y_test_pred)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:22.918965Z","iopub.execute_input":"2023-05-29T20:13:22.919706Z","iopub.status.idle":"2023-05-29T20:13:22.926241Z","shell.execute_reply.started":"2023-05-29T20:13:22.919666Z","shell.execute_reply":"2023-05-29T20:13:22.924637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"misclassification_mask = y_test_class_name != y_test_pred_class_name","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:27.353718Z","iopub.execute_input":"2023-05-29T20:13:27.355143Z","iopub.status.idle":"2023-05-29T20:13:27.360155Z","shell.execute_reply.started":"2023-05-29T20:13:27.3551Z","shell.execute_reply":"2023-05-29T20:13:27.358794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sheep_error_mask = misclassification_mask & (y_test_class_name == \"Alec Baldwin\")\n\nnp.argwhere(sheep_error_mask)[:3]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:28.604662Z","iopub.execute_input":"2023-05-29T20:13:28.605064Z","iopub.status.idle":"2023-05-29T20:13:28.611992Z","shell.execute_reply.started":"2023-05-29T20:13:28.605037Z","shell.execute_reply":"2023-05-29T20:13:28.61118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_idx = 18\n\nplt.imshow(X_test[img_idx])\nplt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T20:13:30.579374Z","iopub.execute_input":"2023-05-29T20:13:30.581032Z","iopub.status.idle":"2023-05-29T20:13:30.831608Z","shell.execute_reply.started":"2023-05-29T20:13:30.580983Z","shell.execute_reply":"2023-05-29T20:13:30.829153Z"},"trusted":true},"execution_count":null,"outputs":[]}]}