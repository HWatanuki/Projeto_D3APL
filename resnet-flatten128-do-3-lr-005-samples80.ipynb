{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **D3APL: Aplicações em Ciência de Dados - IFSP Campinas**\n\n**Professor:** Dr. Samuel Martins (Samuka)\n\n**Alunos:**\n\n* Gabrielly Baratella de Carvalho \n* Halisson Gomides de Souza\n* Hugo Martinelli Watanuki","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-11T07:53:00.666347Z","iopub.status.idle":"2023-06-11T07:53:00.666793Z","shell.execute_reply.started":"2023-06-11T07:53:00.666564Z","shell.execute_reply":"2023-06-11T07:53:00.666585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Celebrity Face Recognition Competition**\n\nThe objetive of this notebook is to document and provide the python code required to address a specific problem of computer vision: the recognition of the faces of celebrities contained in a public dataset ([http://www.briancbecker.com/blog/research/pubfig83-lfw-dataset/](http://))\n\nThis notebook is structured in five main sections that also represent the main steps adopted to address the problem:\n1. Profile the dataset\n1. Pre-process the images\n1. Define the proper neural network\n1. Train the model\n1. Fine-tune the model\n1. Validate the results\n\nThe main approach adopted to address the problem involved addressing the class imbalance of the training dataset using undersampling and the leveraging of a pre-trained face recognition model (VGGFace2 - Resnet) for transfer learning.","metadata":{}},{"cell_type":"markdown","source":"# 1. Profilling the Dataset\n\nThe objetive of this step is to understand the dataset structure, handle the class imbalance and generating a dataframe.","metadata":{}},{"cell_type":"code","source":"# Listing important libraries required for profilling\nimport glob  \nimport os\nimport pandas as pd\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:39:02.257495Z","iopub.execute_input":"2023-06-11T22:39:02.258051Z","iopub.status.idle":"2023-06-11T22:39:02.264560Z","shell.execute_reply.started":"2023-06-11T22:39:02.258002Z","shell.execute_reply":"2023-06-11T22:39:02.263436Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 The Dataset\n\nThe dataset utilized in this competition is a combination of the [PubFigg83](http://vision.seas.harvard.edu/pubfig83/) and [LFW](http://vis-www.cs.umass.edu/lfw/).\n\nThe dataset has 13,840 color images of 83 celebrities and has been previously reshaped to a 100x100 pixels dimension according to the position of the eyes of the individual in the image. 12,1280 images compose the labeled training dataset and 1,660 unlabeled images compose the test dataset. \n\nThe dataset is located on the '/kaggle/input/' directory of the current kernel.","metadata":{}},{"cell_type":"code","source":"# Defining the dataset_folder and evaluating the number of classes\ndataset_folder = '../input/ifsp-d3apl-2023-face-recognition/train/train/'\n\nclass_folders = sorted(os.listdir(dataset_folder))\n\nprint(class_folders)\nprint(f'Number of class: {len(class_folders)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:32:17.636486Z","iopub.execute_input":"2023-06-11T22:32:17.636934Z","iopub.status.idle":"2023-06-11T22:32:17.658271Z","shell.execute_reply.started":"2023-06-11T22:32:17.636898Z","shell.execute_reply":"2023-06-11T22:32:17.656878Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['Adam Sandler', 'Alec Baldwin', 'Angelina Jolie', 'Anna Kournikova', 'Ashton Kutcher', 'Avril Lavigne', 'Barack Obama', 'Ben Affleck', 'Beyonce Knowles', 'Brad Pitt', 'Cameron Diaz', 'Cate Blanchett', 'Charlize Theron', 'Christina Ricci', 'Claudia Schiffer', 'Clive Owen', 'Colin Farrell', 'Colin Powell', 'Cristiano Ronaldo', 'Daniel Craig', 'Daniel Radcliffe', 'David Beckham', 'David Duchovny', 'Denise Richards', 'Drew Barrymore', 'Dustin Hoffman', 'Ehud Olmert', 'Eva Mendes', 'Faith Hill', 'George Clooney', 'Gordon Brown', 'Gwyneth Paltrow', 'Halle Berry', 'Harrison Ford', 'Hugh Jackman', 'Hugh Laurie', 'Jack Nicholson', 'Jennifer Aniston', 'Jennifer Lopez', 'Jennifer Love Hewitt', 'Jessica Alba', 'Jessica Simpson', 'Joaquin Phoenix', 'John Travolta', 'Julia Roberts', 'Julia Stiles', 'Kate Moss', 'Kate Winslet', 'Katherine Heigl', 'Keira Knightley', 'Kiefer Sutherland', 'Leonardo DiCaprio', 'Lindsay Lohan', 'Mariah Carey', 'Martha Stewart', 'Matt Damon', 'Meg Ryan', 'Meryl Streep', 'Michael Bloomberg', 'Mickey Rourke', 'Miley Cyrus', 'Morgan Freeman', 'Nicole Kidman', 'Nicole Richie', 'Orlando Bloom', 'Reese Witherspoon', 'Renee Zellweger', 'Ricky Martin', 'Robert Gates', 'Sania Mirza', 'Scarlett Johansson', 'Shahrukh Khan', 'Shakira', 'Sharon Stone', 'Silvio Berlusconi', 'Stephen Colbert', 'Steve Carell', 'Tom Cruise', 'Uma Thurman', 'Victoria Beckham', 'Viggo Mortensen', 'Will Smith', 'Zac Efron']\nNumber of class: 83\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the class proportions: number of samples per class\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    \n    class_img_filenames = os.listdir(full_class_folder)\n    print(f'Number of Images for Class \"{class_folder}\": {len(class_img_filenames)}')","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:32:20.199711Z","iopub.execute_input":"2023-06-11T22:32:20.200187Z","iopub.status.idle":"2023-06-11T22:32:22.840126Z","shell.execute_reply.started":"2023-06-11T22:32:20.200154Z","shell.execute_reply":"2023-06-11T22:32:22.838966Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of Images for Class \"Adam Sandler\": 88\nNumber of Images for Class \"Alec Baldwin\": 83\nNumber of Images for Class \"Angelina Jolie\": 194\nNumber of Images for Class \"Anna Kournikova\": 151\nNumber of Images for Class \"Ashton Kutcher\": 81\nNumber of Images for Class \"Avril Lavigne\": 279\nNumber of Images for Class \"Barack Obama\": 249\nNumber of Images for Class \"Ben Affleck\": 97\nNumber of Images for Class \"Beyonce Knowles\": 106\nNumber of Images for Class \"Brad Pitt\": 280\nNumber of Images for Class \"Cameron Diaz\": 226\nNumber of Images for Class \"Cate Blanchett\": 140\nNumber of Images for Class \"Charlize Theron\": 175\nNumber of Images for Class \"Christina Ricci\": 123\nNumber of Images for Class \"Claudia Schiffer\": 102\nNumber of Images for Class \"Clive Owen\": 114\nNumber of Images for Class \"Colin Farrell\": 125\nNumber of Images for Class \"Colin Powell\": 92\nNumber of Images for Class \"Cristiano Ronaldo\": 148\nNumber of Images for Class \"Daniel Craig\": 148\nNumber of Images for Class \"Daniel Radcliffe\": 226\nNumber of Images for Class \"David Beckham\": 167\nNumber of Images for Class \"David Duchovny\": 129\nNumber of Images for Class \"Denise Richards\": 180\nNumber of Images for Class \"Drew Barrymore\": 132\nNumber of Images for Class \"Dustin Hoffman\": 80\nNumber of Images for Class \"Ehud Olmert\": 110\nNumber of Images for Class \"Eva Mendes\": 115\nNumber of Images for Class \"Faith Hill\": 95\nNumber of Images for Class \"George Clooney\": 207\nNumber of Images for Class \"Gordon Brown\": 82\nNumber of Images for Class \"Gwyneth Paltrow\": 233\nNumber of Images for Class \"Halle Berry\": 90\nNumber of Images for Class \"Harrison Ford\": 130\nNumber of Images for Class \"Hugh Jackman\": 137\nNumber of Images for Class \"Hugh Laurie\": 148\nNumber of Images for Class \"Jack Nicholson\": 81\nNumber of Images for Class \"Jennifer Aniston\": 210\nNumber of Images for Class \"Jennifer Lopez\": 109\nNumber of Images for Class \"Jennifer Love Hewitt\": 87\nNumber of Images for Class \"Jessica Alba\": 155\nNumber of Images for Class \"Jessica Simpson\": 280\nNumber of Images for Class \"Joaquin Phoenix\": 88\nNumber of Images for Class \"John Travolta\": 112\nNumber of Images for Class \"Julia Roberts\": 112\nNumber of Images for Class \"Julia Stiles\": 112\nNumber of Images for Class \"Kate Moss\": 133\nNumber of Images for Class \"Kate Winslet\": 114\nNumber of Images for Class \"Katherine Heigl\": 237\nNumber of Images for Class \"Keira Knightley\": 175\nNumber of Images for Class \"Kiefer Sutherland\": 115\nNumber of Images for Class \"Leonardo DiCaprio\": 179\nNumber of Images for Class \"Lindsay Lohan\": 334\nNumber of Images for Class \"Mariah Carey\": 82\nNumber of Images for Class \"Martha Stewart\": 88\nNumber of Images for Class \"Matt Damon\": 134\nNumber of Images for Class \"Meg Ryan\": 190\nNumber of Images for Class \"Meryl Streep\": 126\nNumber of Images for Class \"Michael Bloomberg\": 82\nNumber of Images for Class \"Mickey Rourke\": 99\nNumber of Images for Class \"Miley Cyrus\": 348\nNumber of Images for Class \"Morgan Freeman\": 88\nNumber of Images for Class \"Nicole Kidman\": 165\nNumber of Images for Class \"Nicole Richie\": 168\nNumber of Images for Class \"Orlando Bloom\": 240\nNumber of Images for Class \"Reese Witherspoon\": 137\nNumber of Images for Class \"Renee Zellweger\": 113\nNumber of Images for Class \"Ricky Martin\": 123\nNumber of Images for Class \"Robert Gates\": 80\nNumber of Images for Class \"Sania Mirza\": 108\nNumber of Images for Class \"Scarlett Johansson\": 253\nNumber of Images for Class \"Shahrukh Khan\": 132\nNumber of Images for Class \"Shakira\": 181\nNumber of Images for Class \"Sharon Stone\": 186\nNumber of Images for Class \"Silvio Berlusconi\": 101\nNumber of Images for Class \"Stephen Colbert\": 104\nNumber of Images for Class \"Steve Carell\": 146\nNumber of Images for Class \"Tom Cruise\": 177\nNumber of Images for Class \"Uma Thurman\": 147\nNumber of Images for Class \"Victoria Beckham\": 114\nNumber of Images for Class \"Viggo Mortensen\": 92\nNumber of Images for Class \"Will Smith\": 108\nNumber of Images for Class \"Zac Efron\": 173\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sorting and identifying the class with the fewest images\n\n# Dictionary to store directory and file count\nfile_counts = {}\n\n# Count files in each directory\nfor class_folder in class_folders:\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    file_counts[class_folder] = len(glob.glob(os.path.join(full_class_folder, '*')))\n\n# Sort file counts by value in descending order\nsorted_counts = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)\n\nprint(sorted_counts)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:32:25.249322Z","iopub.execute_input":"2023-06-11T22:32:25.249778Z","iopub.status.idle":"2023-06-11T22:32:25.379210Z","shell.execute_reply.started":"2023-06-11T22:32:25.249745Z","shell.execute_reply":"2023-06-11T22:32:25.378142Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[('Miley Cyrus', 348), ('Lindsay Lohan', 334), ('Brad Pitt', 280), ('Jessica Simpson', 280), ('Avril Lavigne', 279), ('Scarlett Johansson', 253), ('Barack Obama', 249), ('Orlando Bloom', 240), ('Katherine Heigl', 237), ('Gwyneth Paltrow', 233), ('Cameron Diaz', 226), ('Daniel Radcliffe', 226), ('Jennifer Aniston', 210), ('George Clooney', 207), ('Angelina Jolie', 194), ('Meg Ryan', 190), ('Sharon Stone', 186), ('Shakira', 181), ('Denise Richards', 180), ('Leonardo DiCaprio', 179), ('Tom Cruise', 177), ('Charlize Theron', 175), ('Keira Knightley', 175), ('Zac Efron', 173), ('Nicole Richie', 168), ('David Beckham', 167), ('Nicole Kidman', 165), ('Jessica Alba', 155), ('Anna Kournikova', 151), ('Cristiano Ronaldo', 148), ('Daniel Craig', 148), ('Hugh Laurie', 148), ('Uma Thurman', 147), ('Steve Carell', 146), ('Cate Blanchett', 140), ('Hugh Jackman', 137), ('Reese Witherspoon', 137), ('Matt Damon', 134), ('Kate Moss', 133), ('Drew Barrymore', 132), ('Shahrukh Khan', 132), ('Harrison Ford', 130), ('David Duchovny', 129), ('Meryl Streep', 126), ('Colin Farrell', 125), ('Christina Ricci', 123), ('Ricky Martin', 123), ('Eva Mendes', 115), ('Kiefer Sutherland', 115), ('Clive Owen', 114), ('Kate Winslet', 114), ('Victoria Beckham', 114), ('Renee Zellweger', 113), ('John Travolta', 112), ('Julia Roberts', 112), ('Julia Stiles', 112), ('Ehud Olmert', 110), ('Jennifer Lopez', 109), ('Sania Mirza', 108), ('Will Smith', 108), ('Beyonce Knowles', 106), ('Stephen Colbert', 104), ('Claudia Schiffer', 102), ('Silvio Berlusconi', 101), ('Mickey Rourke', 99), ('Ben Affleck', 97), ('Faith Hill', 95), ('Colin Powell', 92), ('Viggo Mortensen', 92), ('Halle Berry', 90), ('Adam Sandler', 88), ('Joaquin Phoenix', 88), ('Martha Stewart', 88), ('Morgan Freeman', 88), ('Jennifer Love Hewitt', 87), ('Alec Baldwin', 83), ('Gordon Brown', 82), ('Mariah Carey', 82), ('Michael Bloomberg', 82), ('Ashton Kutcher', 81), ('Jack Nicholson', 81), ('Dustin Hoffman', 80), ('Robert Gates', 80)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.2 Handling the Class Imbalance by Undersampling\n\nThe class with the fewest images is \"Robert Gates\" (80 images) and the one with the most images is \"Miley Cyrus\" (348 images).\n\nWe have decided to adopt a undersampling technique to handle the class imbalance issue.\n\nDue to memory hard limits in the kernel and the fact that the pre-trained model does not accept multiprocessing we have decided to consider 50 images per class for the training.","metadata":{}},{"cell_type":"code","source":"# Defining the maximum number of images per class\nmax_n_samples_per_class = 50","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:32:28.547941Z","iopub.execute_input":"2023-06-11T22:32:28.548433Z","iopub.status.idle":"2023-06-11T22:32:28.554804Z","shell.execute_reply.started":"2023-06-11T22:32:28.548395Z","shell.execute_reply":"2023-06-11T22:32:28.553077Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Ramdonly selecting 50 images from each class \ndataset_folder = '../input/ifsp-d3apl-2023-face-recognition/train/train/'\nclass_folders = sorted(os.listdir(dataset_folder))\n\n# OPTIONAL: just to get the same selected images\nrandom.seed(22)\n\nimg_full_paths = []\nimg_classes = []\n\nfor class_folder in class_folders:\n    img_class = class_folder  \n    print(f'Class: {img_class}')\n     \n    # get the full class folder pathname\n    full_class_folder = os.path.join(dataset_folder, class_folder)\n    print(full_class_folder)\n    \n    # get all image filenames (without their parent dir) for the current class/celebrity\n    class_img_filenames = sorted(os.listdir(full_class_folder))\n    print(len(class_img_filenames))\n    \n    class_img_filenames = random.sample(class_img_filenames, max_n_samples_per_class)\n    print(f'Number of images: {len(class_img_filenames)}')\n    \n    for img_filename in class_img_filenames:\n        full_img_path = os.path.join(full_class_folder, img_filename)\n        \n        img_full_paths.append(full_img_path)\n        img_classes.append(img_class)\n\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:35:55.303773Z","iopub.execute_input":"2023-06-11T22:35:55.304303Z","iopub.status.idle":"2023-06-11T22:35:55.409703Z","shell.execute_reply.started":"2023-06-11T22:35:55.304265Z","shell.execute_reply":"2023-06-11T22:35:55.408767Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Class: Adam Sandler\n../input/ifsp-d3apl-2023-face-recognition/train/train/Adam Sandler\n88\nNumber of images: 50\n\nClass: Alec Baldwin\n../input/ifsp-d3apl-2023-face-recognition/train/train/Alec Baldwin\n83\nNumber of images: 50\n\nClass: Angelina Jolie\n../input/ifsp-d3apl-2023-face-recognition/train/train/Angelina Jolie\n194\nNumber of images: 50\n\nClass: Anna Kournikova\n../input/ifsp-d3apl-2023-face-recognition/train/train/Anna Kournikova\n151\nNumber of images: 50\n\nClass: Ashton Kutcher\n../input/ifsp-d3apl-2023-face-recognition/train/train/Ashton Kutcher\n81\nNumber of images: 50\n\nClass: Avril Lavigne\n../input/ifsp-d3apl-2023-face-recognition/train/train/Avril Lavigne\n279\nNumber of images: 50\n\nClass: Barack Obama\n../input/ifsp-d3apl-2023-face-recognition/train/train/Barack Obama\n249\nNumber of images: 50\n\nClass: Ben Affleck\n../input/ifsp-d3apl-2023-face-recognition/train/train/Ben Affleck\n97\nNumber of images: 50\n\nClass: Beyonce Knowles\n../input/ifsp-d3apl-2023-face-recognition/train/train/Beyonce Knowles\n106\nNumber of images: 50\n\nClass: Brad Pitt\n../input/ifsp-d3apl-2023-face-recognition/train/train/Brad Pitt\n280\nNumber of images: 50\n\nClass: Cameron Diaz\n../input/ifsp-d3apl-2023-face-recognition/train/train/Cameron Diaz\n226\nNumber of images: 50\n\nClass: Cate Blanchett\n../input/ifsp-d3apl-2023-face-recognition/train/train/Cate Blanchett\n140\nNumber of images: 50\n\nClass: Charlize Theron\n../input/ifsp-d3apl-2023-face-recognition/train/train/Charlize Theron\n175\nNumber of images: 50\n\nClass: Christina Ricci\n../input/ifsp-d3apl-2023-face-recognition/train/train/Christina Ricci\n123\nNumber of images: 50\n\nClass: Claudia Schiffer\n../input/ifsp-d3apl-2023-face-recognition/train/train/Claudia Schiffer\n102\nNumber of images: 50\n\nClass: Clive Owen\n../input/ifsp-d3apl-2023-face-recognition/train/train/Clive Owen\n114\nNumber of images: 50\n\nClass: Colin Farrell\n../input/ifsp-d3apl-2023-face-recognition/train/train/Colin Farrell\n125\nNumber of images: 50\n\nClass: Colin Powell\n../input/ifsp-d3apl-2023-face-recognition/train/train/Colin Powell\n92\nNumber of images: 50\n\nClass: Cristiano Ronaldo\n../input/ifsp-d3apl-2023-face-recognition/train/train/Cristiano Ronaldo\n148\nNumber of images: 50\n\nClass: Daniel Craig\n../input/ifsp-d3apl-2023-face-recognition/train/train/Daniel Craig\n148\nNumber of images: 50\n\nClass: Daniel Radcliffe\n../input/ifsp-d3apl-2023-face-recognition/train/train/Daniel Radcliffe\n226\nNumber of images: 50\n\nClass: David Beckham\n../input/ifsp-d3apl-2023-face-recognition/train/train/David Beckham\n167\nNumber of images: 50\n\nClass: David Duchovny\n../input/ifsp-d3apl-2023-face-recognition/train/train/David Duchovny\n129\nNumber of images: 50\n\nClass: Denise Richards\n../input/ifsp-d3apl-2023-face-recognition/train/train/Denise Richards\n180\nNumber of images: 50\n\nClass: Drew Barrymore\n../input/ifsp-d3apl-2023-face-recognition/train/train/Drew Barrymore\n132\nNumber of images: 50\n\nClass: Dustin Hoffman\n../input/ifsp-d3apl-2023-face-recognition/train/train/Dustin Hoffman\n80\nNumber of images: 50\n\nClass: Ehud Olmert\n../input/ifsp-d3apl-2023-face-recognition/train/train/Ehud Olmert\n110\nNumber of images: 50\n\nClass: Eva Mendes\n../input/ifsp-d3apl-2023-face-recognition/train/train/Eva Mendes\n115\nNumber of images: 50\n\nClass: Faith Hill\n../input/ifsp-d3apl-2023-face-recognition/train/train/Faith Hill\n95\nNumber of images: 50\n\nClass: George Clooney\n../input/ifsp-d3apl-2023-face-recognition/train/train/George Clooney\n207\nNumber of images: 50\n\nClass: Gordon Brown\n../input/ifsp-d3apl-2023-face-recognition/train/train/Gordon Brown\n82\nNumber of images: 50\n\nClass: Gwyneth Paltrow\n../input/ifsp-d3apl-2023-face-recognition/train/train/Gwyneth Paltrow\n233\nNumber of images: 50\n\nClass: Halle Berry\n../input/ifsp-d3apl-2023-face-recognition/train/train/Halle Berry\n90\nNumber of images: 50\n\nClass: Harrison Ford\n../input/ifsp-d3apl-2023-face-recognition/train/train/Harrison Ford\n130\nNumber of images: 50\n\nClass: Hugh Jackman\n../input/ifsp-d3apl-2023-face-recognition/train/train/Hugh Jackman\n137\nNumber of images: 50\n\nClass: Hugh Laurie\n../input/ifsp-d3apl-2023-face-recognition/train/train/Hugh Laurie\n148\nNumber of images: 50\n\nClass: Jack Nicholson\n../input/ifsp-d3apl-2023-face-recognition/train/train/Jack Nicholson\n81\nNumber of images: 50\n\nClass: Jennifer Aniston\n../input/ifsp-d3apl-2023-face-recognition/train/train/Jennifer Aniston\n210\nNumber of images: 50\n\nClass: Jennifer Lopez\n../input/ifsp-d3apl-2023-face-recognition/train/train/Jennifer Lopez\n109\nNumber of images: 50\n\nClass: Jennifer Love Hewitt\n../input/ifsp-d3apl-2023-face-recognition/train/train/Jennifer Love Hewitt\n87\nNumber of images: 50\n\nClass: Jessica Alba\n../input/ifsp-d3apl-2023-face-recognition/train/train/Jessica Alba\n155\nNumber of images: 50\n\nClass: Jessica Simpson\n../input/ifsp-d3apl-2023-face-recognition/train/train/Jessica Simpson\n280\nNumber of images: 50\n\nClass: Joaquin Phoenix\n../input/ifsp-d3apl-2023-face-recognition/train/train/Joaquin Phoenix\n88\nNumber of images: 50\n\nClass: John Travolta\n../input/ifsp-d3apl-2023-face-recognition/train/train/John Travolta\n112\nNumber of images: 50\n\nClass: Julia Roberts\n../input/ifsp-d3apl-2023-face-recognition/train/train/Julia Roberts\n112\nNumber of images: 50\n\nClass: Julia Stiles\n../input/ifsp-d3apl-2023-face-recognition/train/train/Julia Stiles\n112\nNumber of images: 50\n\nClass: Kate Moss\n../input/ifsp-d3apl-2023-face-recognition/train/train/Kate Moss\n133\nNumber of images: 50\n\nClass: Kate Winslet\n../input/ifsp-d3apl-2023-face-recognition/train/train/Kate Winslet\n114\nNumber of images: 50\n\nClass: Katherine Heigl\n../input/ifsp-d3apl-2023-face-recognition/train/train/Katherine Heigl\n237\nNumber of images: 50\n\nClass: Keira Knightley\n../input/ifsp-d3apl-2023-face-recognition/train/train/Keira Knightley\n175\nNumber of images: 50\n\nClass: Kiefer Sutherland\n../input/ifsp-d3apl-2023-face-recognition/train/train/Kiefer Sutherland\n115\nNumber of images: 50\n\nClass: Leonardo DiCaprio\n../input/ifsp-d3apl-2023-face-recognition/train/train/Leonardo DiCaprio\n179\nNumber of images: 50\n\nClass: Lindsay Lohan\n../input/ifsp-d3apl-2023-face-recognition/train/train/Lindsay Lohan\n334\nNumber of images: 50\n\nClass: Mariah Carey\n../input/ifsp-d3apl-2023-face-recognition/train/train/Mariah Carey\n82\nNumber of images: 50\n\nClass: Martha Stewart\n../input/ifsp-d3apl-2023-face-recognition/train/train/Martha Stewart\n88\nNumber of images: 50\n\nClass: Matt Damon\n../input/ifsp-d3apl-2023-face-recognition/train/train/Matt Damon\n134\nNumber of images: 50\n\nClass: Meg Ryan\n../input/ifsp-d3apl-2023-face-recognition/train/train/Meg Ryan\n190\nNumber of images: 50\n\nClass: Meryl Streep\n../input/ifsp-d3apl-2023-face-recognition/train/train/Meryl Streep\n126\nNumber of images: 50\n\nClass: Michael Bloomberg\n../input/ifsp-d3apl-2023-face-recognition/train/train/Michael Bloomberg\n82\nNumber of images: 50\n\nClass: Mickey Rourke\n../input/ifsp-d3apl-2023-face-recognition/train/train/Mickey Rourke\n99\nNumber of images: 50\n\nClass: Miley Cyrus\n../input/ifsp-d3apl-2023-face-recognition/train/train/Miley Cyrus\n348\nNumber of images: 50\n\nClass: Morgan Freeman\n../input/ifsp-d3apl-2023-face-recognition/train/train/Morgan Freeman\n88\nNumber of images: 50\n\nClass: Nicole Kidman\n../input/ifsp-d3apl-2023-face-recognition/train/train/Nicole Kidman\n165\nNumber of images: 50\n\nClass: Nicole Richie\n../input/ifsp-d3apl-2023-face-recognition/train/train/Nicole Richie\n168\nNumber of images: 50\n\nClass: Orlando Bloom\n../input/ifsp-d3apl-2023-face-recognition/train/train/Orlando Bloom\n240\nNumber of images: 50\n\nClass: Reese Witherspoon\n../input/ifsp-d3apl-2023-face-recognition/train/train/Reese Witherspoon\n137\nNumber of images: 50\n\nClass: Renee Zellweger\n../input/ifsp-d3apl-2023-face-recognition/train/train/Renee Zellweger\n113\nNumber of images: 50\n\nClass: Ricky Martin\n../input/ifsp-d3apl-2023-face-recognition/train/train/Ricky Martin\n123\nNumber of images: 50\n\nClass: Robert Gates\n../input/ifsp-d3apl-2023-face-recognition/train/train/Robert Gates\n80\nNumber of images: 50\n\nClass: Sania Mirza\n../input/ifsp-d3apl-2023-face-recognition/train/train/Sania Mirza\n108\nNumber of images: 50\n\nClass: Scarlett Johansson\n../input/ifsp-d3apl-2023-face-recognition/train/train/Scarlett Johansson\n253\nNumber of images: 50\n\nClass: Shahrukh Khan\n../input/ifsp-d3apl-2023-face-recognition/train/train/Shahrukh Khan\n132\nNumber of images: 50\n\nClass: Shakira\n../input/ifsp-d3apl-2023-face-recognition/train/train/Shakira\n181\nNumber of images: 50\n\nClass: Sharon Stone\n../input/ifsp-d3apl-2023-face-recognition/train/train/Sharon Stone\n186\nNumber of images: 50\n\nClass: Silvio Berlusconi\n../input/ifsp-d3apl-2023-face-recognition/train/train/Silvio Berlusconi\n101\nNumber of images: 50\n\nClass: Stephen Colbert\n../input/ifsp-d3apl-2023-face-recognition/train/train/Stephen Colbert\n104\nNumber of images: 50\n\nClass: Steve Carell\n../input/ifsp-d3apl-2023-face-recognition/train/train/Steve Carell\n146\nNumber of images: 50\n\nClass: Tom Cruise\n../input/ifsp-d3apl-2023-face-recognition/train/train/Tom Cruise\n177\nNumber of images: 50\n\nClass: Uma Thurman\n../input/ifsp-d3apl-2023-face-recognition/train/train/Uma Thurman\n147\nNumber of images: 50\n\nClass: Victoria Beckham\n../input/ifsp-d3apl-2023-face-recognition/train/train/Victoria Beckham\n114\nNumber of images: 50\n\nClass: Viggo Mortensen\n../input/ifsp-d3apl-2023-face-recognition/train/train/Viggo Mortensen\n92\nNumber of images: 50\n\nClass: Will Smith\n../input/ifsp-d3apl-2023-face-recognition/train/train/Will Smith\n108\nNumber of images: 50\n\nClass: Zac Efron\n../input/ifsp-d3apl-2023-face-recognition/train/train/Zac Efron\n173\nNumber of images: 50\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assessing the total number of images (50 images x 83 classes = 4,150)\nprint(len(img_full_paths))\nprint(len(img_classes))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:38:16.323318Z","iopub.execute_input":"2023-06-11T22:38:16.323728Z","iopub.status.idle":"2023-06-11T22:38:16.331369Z","shell.execute_reply.started":"2023-06-11T22:38:16.323697Z","shell.execute_reply":"2023-06-11T22:38:16.329458Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"4150\n4150\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating a dataframe to store the image full pathnames and their corresponding classes\ndataset_df = pd.DataFrame({\n    'image_pathname': img_full_paths,\n    'class': img_classes\n})\n\ndataset_df","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:39:12.602320Z","iopub.execute_input":"2023-06-11T22:39:12.602813Z","iopub.status.idle":"2023-06-11T22:39:12.652936Z","shell.execute_reply.started":"2023-06-11T22:39:12.602774Z","shell.execute_reply":"2023-06-11T22:39:12.651596Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                         image_pathname         class\n0     ../input/ifsp-d3apl-2023-face-recognition/trai...  Adam Sandler\n1     ../input/ifsp-d3apl-2023-face-recognition/trai...  Adam Sandler\n2     ../input/ifsp-d3apl-2023-face-recognition/trai...  Adam Sandler\n3     ../input/ifsp-d3apl-2023-face-recognition/trai...  Adam Sandler\n4     ../input/ifsp-d3apl-2023-face-recognition/trai...  Adam Sandler\n...                                                 ...           ...\n4145  ../input/ifsp-d3apl-2023-face-recognition/trai...     Zac Efron\n4146  ../input/ifsp-d3apl-2023-face-recognition/trai...     Zac Efron\n4147  ../input/ifsp-d3apl-2023-face-recognition/trai...     Zac Efron\n4148  ../input/ifsp-d3apl-2023-face-recognition/trai...     Zac Efron\n4149  ../input/ifsp-d3apl-2023-face-recognition/trai...     Zac Efron\n\n[4150 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_pathname</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Adam Sandler</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Adam Sandler</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Adam Sandler</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Adam Sandler</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Adam Sandler</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4145</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Zac Efron</td>\n    </tr>\n    <tr>\n      <th>4146</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Zac Efron</td>\n    </tr>\n    <tr>\n      <th>4147</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Zac Efron</td>\n    </tr>\n    <tr>\n      <th>4148</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Zac Efron</td>\n    </tr>\n    <tr>\n      <th>4149</th>\n      <td>../input/ifsp-d3apl-2023-face-recognition/trai...</td>\n      <td>Zac Efron</td>\n    </tr>\n  </tbody>\n</table>\n<p>4150 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Listing the counts for the images of each class\ndataset_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:39:52.977001Z","iopub.execute_input":"2023-06-11T22:39:52.977468Z","iopub.status.idle":"2023-06-11T22:39:52.997108Z","shell.execute_reply.started":"2023-06-11T22:39:52.977433Z","shell.execute_reply":"2023-06-11T22:39:52.995648Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Adam Sandler         50\nNicole Kidman        50\nMiley Cyrus          50\nMickey Rourke        50\nMichael Bloomberg    50\n                     ..\nEhud Olmert          50\nDustin Hoffman       50\nDrew Barrymore       50\nDenise Richards      50\nZac Efron            50\nName: class, Length: 83, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Saving the undersampled dataset\ndataset_df.to_csv('../working/faces_dataset_balanced.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T22:41:56.928587Z","iopub.execute_input":"2023-06-11T22:41:56.929322Z","iopub.status.idle":"2023-06-11T22:41:56.977086Z","shell.execute_reply.started":"2023-06-11T22:41:56.929274Z","shell.execute_reply":"2023-06-11T22:41:56.975611Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"CAUTION:\nThe image pathnames shown in the the CSV contain a relative path according to the directory of this notebook.\nIf you try to open some image from a notebook started on other location, an error will appear.\nOne solution is to save the absolute path of each image or simply adjust the relative path according to your need.","metadata":{}},{"cell_type":"markdown","source":"# 1.5 Inspecting an image","metadata":{}},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.714949Z","iopub.status.idle":"2023-06-11T07:53:00.715776Z","shell.execute_reply.started":"2023-06-11T07:53:00.715522Z","shell.execute_reply":"2023-06-11T07:53:00.715546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df.loc[0, 'image_pathname']","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.717242Z","iopub.status.idle":"2023-06-11T07:53:00.718128Z","shell.execute_reply.started":"2023-06-11T07:53:00.717869Z","shell.execute_reply":"2023-06-11T07:53:00.717892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read an image\nimg = cv2.imread(dataset_df.loc[0, 'image_pathname'])\nprint(type(img))\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.719767Z","iopub.status.idle":"2023-06-11T07:53:00.720633Z","shell.execute_reply.started":"2023-06-11T07:53:00.720384Z","shell.execute_reply":"2023-06-11T07:53:00.720409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel BLUE\nimg[:, :, 0]","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.724407Z","iopub.status.idle":"2023-06-11T07:53:00.725184Z","shell.execute_reply.started":"2023-06-11T07:53:00.724939Z","shell.execute_reply":"2023-06-11T07:53:00.724962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel GREEN\nimg[:, :, 1]","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.726595Z","iopub.status.idle":"2023-06-11T07:53:00.727374Z","shell.execute_reply.started":"2023-06-11T07:53:00.727106Z","shell.execute_reply":"2023-06-11T07:53:00.727128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# channel RED\nimg[:, :, 2]","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.728804Z","iopub.status.idle":"2023-06-11T07:53:00.729608Z","shell.execute_reply.started":"2023-06-11T07:53:00.729371Z","shell.execute_reply":"2023-06-11T07:53:00.729394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.min(), img.max()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.731281Z","iopub.status.idle":"2023-06-11T07:53:00.732076Z","shell.execute_reply.started":"2023-06-11T07:53:00.731823Z","shell.execute_reply":"2023-06-11T07:53:00.731845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.734279Z","iopub.status.idle":"2023-06-11T07:53:00.735108Z","shell.execute_reply.started":"2023-06-11T07:53:00.734872Z","shell.execute_reply":"2023-06-11T07:53:00.734894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#img_RGB = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\nplt.imshow(img_RGB)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.736537Z","iopub.status.idle":"2023-06-11T07:53:00.737421Z","shell.execute_reply.started":"2023-06-11T07:53:00.737126Z","shell.execute_reply":"2023-06-11T07:53:00.737164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(dataset_df.loc[500, 'image_pathname'])  # BGR\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert BGR to RGB\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.739633Z","iopub.status.idle":"2023-06-11T07:53:00.740925Z","shell.execute_reply.started":"2023-06-11T07:53:00.740563Z","shell.execute_reply":"2023-06-11T07:53:00.740591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.743063Z","iopub.status.idle":"2023-06-11T07:53:00.744228Z","shell.execute_reply.started":"2023-06-11T07:53:00.743862Z","shell.execute_reply":"2023-06-11T07:53:00.743887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.6 Create the training dataset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.746459Z","iopub.status.idle":"2023-06-11T07:53:00.747686Z","shell.execute_reply.started":"2023-06-11T07:53:00.747288Z","shell.execute_reply":"2023-06-11T07:53:00.747349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.749941Z","iopub.status.idle":"2023-06-11T07:53:00.750904Z","shell.execute_reply.started":"2023-06-11T07:53:00.75065Z","shell.execute_reply":"2023-06-11T07:53:00.750673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\n\nif gpus:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.752339Z","iopub.status.idle":"2023-06-11T07:53:00.753171Z","shell.execute_reply.started":"2023-06-11T07:53:00.752902Z","shell.execute_reply":"2023-06-11T07:53:00.752928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.75469Z","iopub.status.idle":"2023-06-11T07:53:00.755589Z","shell.execute_reply.started":"2023-06-11T07:53:00.755285Z","shell.execute_reply":"2023-06-11T07:53:00.755334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df[\"class\"].unique()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.761353Z","iopub.status.idle":"2023-06-11T07:53:00.762113Z","shell.execute_reply.started":"2023-06-11T07:53:00.761873Z","shell.execute_reply":"2023-06-11T07:53:00.761895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = sorted(dataset_df[\"class\"].unique())\nn_classes = len(class_names)\n\nprint(f'Number of classes: {n_classes}')\nprint(f'Classes: {class_names}')","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.766979Z","iopub.status.idle":"2023-06-11T07:53:00.768438Z","shell.execute_reply.started":"2023-06-11T07:53:00.767966Z","shell.execute_reply":"2023-06-11T07:53:00.768049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of samples per class\ndataset_df['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.769653Z","iopub.status.idle":"2023-06-11T07:53:00.770359Z","shell.execute_reply.started":"2023-06-11T07:53:00.770125Z","shell.execute_reply":"2023-06-11T07:53:00.770145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# for a stratified sampling, we need to pass the labels\nlabels = dataset_df['class']\n\ndataset_df_full_train, dataset_df_test = train_test_split(dataset_df, test_size=0.2, random_state=22, stratify=labels)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.773582Z","iopub.status.idle":"2023-06-11T07:53:00.774281Z","shell.execute_reply.started":"2023-06-11T07:53:00.774067Z","shell.execute_reply":"2023-06-11T07:53:00.774087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_full_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.775745Z","iopub.status.idle":"2023-06-11T07:53:00.77654Z","shell.execute_reply.started":"2023-06-11T07:53:00.776274Z","shell.execute_reply":"2023-06-11T07:53:00.776297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_full_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.777931Z","iopub.status.idle":"2023-06-11T07:53:00.779197Z","shell.execute_reply.started":"2023-06-11T07:53:00.778726Z","shell.execute_reply":"2023-06-11T07:53:00.778791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.782353Z","iopub.status.idle":"2023-06-11T07:53:00.786685Z","shell.execute_reply.started":"2023-06-11T07:53:00.78641Z","shell.execute_reply":"2023-06-11T07:53:00.786437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for a stratified sampling, we need to pass the labels\nlabels_full_train = dataset_df_full_train['class']\n#labels = dataset_df['class']\n\ndataset_df_train, dataset_df_val = train_test_split(dataset_df_full_train, train_size=0.8, random_state=22, stratify=labels_full_train)\n#dataset_df_train, dataset_df_val = train_test_split(dataset_df, train_size=0.8, random_state=42, stratify=labels)\n\ndataset_df_train['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.78835Z","iopub.status.idle":"2023-06-11T07:53:00.789217Z","shell.execute_reply.started":"2023-06-11T07:53:00.788955Z","shell.execute_reply":"2023-06-11T07:53:00.788978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking class balancing in the validation set\ndataset_df_val['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.790745Z","iopub.status.idle":"2023-06-11T07:53:00.791912Z","shell.execute_reply.started":"2023-06-11T07:53:00.791652Z","shell.execute_reply":"2023-06-11T07:53:00.791677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df_test['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.798774Z","iopub.status.idle":"2023-06-11T07:53:00.799563Z","shell.execute_reply.started":"2023-06-11T07:53:00.7993Z","shell.execute_reply":"2023-06-11T07:53:00.799343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.7 Preprocessing the images","metadata":{}},{"cell_type":"code","source":"dataset_df.loc[0, 'image_pathname']","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.801012Z","iopub.status.idle":"2023-06-11T07:53:00.801789Z","shell.execute_reply.started":"2023-06-11T07:53:00.801546Z","shell.execute_reply":"2023-06-11T07:53:00.801569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n# BGR\nimg = cv2.imread('../working/oversampled/Adam Sandler/73.jpg')\n# BGR ==> RGB\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.803183Z","iopub.status.idle":"2023-06-11T07:53:00.804034Z","shell.execute_reply.started":"2023-06-11T07:53:00.803777Z","shell.execute_reply":"2023-06-11T07:53:00.803801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aspect ratio = width / height\naspect_ratio = img.shape[0] / img.shape[1]\naspect_ratio","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.807007Z","iopub.status.idle":"2023-06-11T07:53:00.807776Z","shell.execute_reply.started":"2023-06-11T07:53:00.807531Z","shell.execute_reply":"2023-06-11T07:53:00.807553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n\n#def preprocess_faces_dataset(dataset_df, label_encoder: LabelEncoder, new_img_dims=(100, 100), verbose=0):\ndef preprocess_faces_dataset(dataset_df, label_encoder: LabelEncoder, new_img_dims=(224, 224), verbose=0):\n    # load the images as a feature matrix\n    image_list = []  # list of numpy arrays\n    \n    for index, img_path in enumerate(dataset_df['image_pathname']):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # image resizing\n        # for gray or color images, the linear interpolation sounds good\n        img = cv2.resize(img, new_img_dims, interpolation=cv2.INTER_LINEAR)        \n        image_list.append(img)\n        \n        if verbose and (index % verbose) == 0:\n            print(f'{index + 1}/{dataset_df.shape[0]} - {img_path}')\n    \n    # numpy array 4D: n_imgs, height, width, n_channels\n    X = np.array(image_list)\n    \n    # feature scaling\n    # numpy arary 4D with values within [0, 1]\n    X = X / 255.0\n    \n    # encoding the classes\n    # numpy array 1D with integer labels\n    y = label_encoder.transform(dataset_df['class'])\n    \n    return X, y","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.809176Z","iopub.status.idle":"2023-06-11T07:53:00.81101Z","shell.execute_reply.started":"2023-06-11T07:53:00.810737Z","shell.execute_reply":"2023-06-11T07:53:00.810761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nimport numpy as np\nimport math\nimport cv2\n\n\nclass MyGenerator(Sequence):\n    def __init__(self, dataset_df, label_encoder, batch_size, new_dims=(100, 100)):\n        self.dataset_df = dataset_df\n        self.label_encoder = label_encoder\n        self.batch_size = batch_size\n        self.new_dims = new_dims\n    \n    \n    def __len__(self):\n        n_samples = self.dataset_df.shape[0]\n        \n        return math.ceil(n_samples / float(self.batch_size))\n    \n    \n    def __getitem__(self, idx):\n        batch_begin = idx * self.batch_size\n        batch_end = (idx + 1) * self.batch_size\n        \n        batch_df = self.dataset_df[batch_begin:batch_end]\n        \n        X_batch, y_batch = preprocess_faces_dataset(batch_df, self.label_encoder, self.new_dims, verbose=0)\n        #X_batch, y_batch = preprocess_faces_dataset(batch_df, self.label_encoder, self.new_dims)\n                \n        return X_batch, y_batch","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.813204Z","iopub.status.idle":"2023-06-11T07:53:00.814097Z","shell.execute_reply.started":"2023-06-11T07:53:00.813808Z","shell.execute_reply":"2023-06-11T07:53:00.813833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training a Label Encoder from the train set\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(dataset_df_train['class'])\n\nlabel_encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.815688Z","iopub.status.idle":"2023-06-11T07:53:00.816472Z","shell.execute_reply.started":"2023-06-11T07:53:00.816201Z","shell.execute_reply":"2023-06-11T07:53:00.816223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#batch_size = 83\n\n#training_batch_generator = MyGenerator(dataset_df_train, label_encoder, batch_size, new_dims=(100, 100))\n#validation_batch_generator = MyGenerator(dataset_df_val, label_encoder, batch_size, new_dims=(100, 100))\n#test_batch_generator = MyGenerator(dataset_df_test, label_encoder, batch_size, new_dims=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.817606Z","iopub.status.idle":"2023-06-11T07:53:00.824888Z","shell.execute_reply.started":"2023-06-11T07:53:00.824625Z","shell.execute_reply":"2023-06-11T07:53:00.82465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_batch_generator = MyGenerator(dataset_df_test, label_encoder, batch_size, new_dims=(100, 100))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.826262Z","iopub.status.idle":"2023-06-11T07:53:00.827039Z","shell.execute_reply.started":"2023-06-11T07:53:00.826788Z","shell.execute_reply":"2023-06-11T07:53:00.82681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform/map the string class to the trained numeric class\n#label_encoder.transform(['Alec Baldwin', 'Claudia Schiffer', 'Zac Efron'])","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.82871Z","iopub.status.idle":"2023-06-11T07:53:00.82958Z","shell.execute_reply.started":"2023-06-11T07:53:00.829292Z","shell.execute_reply":"2023-06-11T07:53:00.829333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing the train set\n#X_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder)\n#X_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder, new_img_dims=(100, 100))\nX_train, y_train = preprocess_faces_dataset(dataset_df_train, label_encoder, new_img_dims=(224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.834795Z","iopub.status.idle":"2023-06-11T07:53:00.835935Z","shell.execute_reply.started":"2023-06-11T07:53:00.835682Z","shell.execute_reply":"2023-06-11T07:53:00.835704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'X_train.shape: {X_train.shape}')\nprint(f'y_train (classes): {np.unique(y_train)}')\nprint(f'y_train.shape: {y_train.shape}')\n\n# rescaled 24-bit color image\nprint(f'Min. value of X_train: {X_train.min()}')\nprint(f'Max. value of X_train: {X_train.max()}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.8374Z","iopub.status.idle":"2023-06-11T07:53:00.838205Z","shell.execute_reply.started":"2023-06-11T07:53:00.837964Z","shell.execute_reply":"2023-06-11T07:53:00.837986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.841252Z","iopub.status.idle":"2023-06-11T07:53:00.843138Z","shell.execute_reply.started":"2023-06-11T07:53:00.842648Z","shell.execute_reply":"2023-06-11T07:53:00.842674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# preprocessing the validation set\n#X_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder)\n#X_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder, new_img_dims=(100, 100))\nX_val, y_val = preprocess_faces_dataset(dataset_df_val, label_encoder, new_img_dims=(224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.845512Z","iopub.status.idle":"2023-06-11T07:53:00.84725Z","shell.execute_reply.started":"2023-06-11T07:53:00.846521Z","shell.execute_reply":"2023-06-11T07:53:00.846784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(f'X_val.shape: {X_val.shape}')\nprint(f'y_val (classes): {np.unique(y_val)}')\nprint(f'y_val.shape: {y_val.shape}')\n\n# rescaled 24-bit color image\nprint(f'Min. value of X_val: {X_val.min()}')\nprint(f'Max. value of X_val: {X_val.max()}\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.849947Z","iopub.status.idle":"2023-06-11T07:53:00.850727Z","shell.execute_reply.started":"2023-06-11T07:53:00.850485Z","shell.execute_reply":"2023-06-11T07:53:00.850507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_val[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.852931Z","iopub.status.idle":"2023-06-11T07:53:00.853818Z","shell.execute_reply.started":"2023-06-11T07:53:00.853529Z","shell.execute_reply":"2023-06-11T07:53:00.853558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing the test set\n#X_test, y_test = preprocess_faces_dataset(dataset_df_test, label_encoder, new_img_dims=(100, 100))\nX_test, y_test = preprocess_faces_dataset(dataset_df_test, label_encoder, new_img_dims=(224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.855492Z","iopub.status.idle":"2023-06-11T07:53:00.856269Z","shell.execute_reply.started":"2023-06-11T07:53:00.856028Z","shell.execute_reply":"2023-06-11T07:53:00.856051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X_test[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.858781Z","iopub.status.idle":"2023-06-11T07:53:00.86021Z","shell.execute_reply.started":"2023-06-11T07:53:00.859778Z","shell.execute_reply":"2023-06-11T07:53:00.859805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.8 Saving the preprocessed data","metadata":{}},{"cell_type":"code","source":"import os\n\nout_dir = '../working/preprocessed'\n\nif not os.path.exists(out_dir):\n    os.makedirs(out_dir)\n    \ndataset_df_full_train.to_csv(os.path.join(out_dir, 'full_train.csv'), index=False)\n\ndataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\nnp.save(os.path.join(out_dir, 'train_data_64x64x3.npy'), X_train)\nnp.save(os.path.join(out_dir, 'train_labels.npy'), y_train)\n\ndataset_df_val.to_csv(os.path.join(out_dir, 'validation.csv'), index=False)\nnp.save(os.path.join(out_dir, 'validation_data_64x64x3.npy'), X_val)\nnp.save(os.path.join(out_dir, 'validation_labels.npy'), y_val)\n\ndataset_df_test.to_csv(os.path.join(out_dir, 'test.csv'), index=False)\nnp.save(os.path.join(out_dir, 'test_data_64x64x3.npy'), X_test)\nnp.save(os.path.join(out_dir, 'test_labels.npy'), y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.862505Z","iopub.status.idle":"2023-06-11T07:53:00.863676Z","shell.execute_reply.started":"2023-06-11T07:53:00.863249Z","shell.execute_reply":"2023-06-11T07:53:00.863294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Training the model","metadata":{}},{"cell_type":"markdown","source":"# 2.1 Stablish base model for transfer learning VGG16","metadata":{}},{"cell_type":"code","source":"'''\n# https://keras.io/api/applications/vgg/\n# https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4\n\nfrom tensorflow.keras.applications import VGG16\n\nbase_model = VGG16(include_top=None,   # we will ignore the top layers that consists of the MLP classifier of VGG16\n                   weights=\"imagenet\", # we will use the weights learned for the ImageNet dataset\n                   input_shape=(100, 100, 3))  # let's consider a smaller resolution than the original paper due to lack of memory\n\n\n# freeze the base model weights ==> these weights won't be updated during training\n# i.e., the weights of all layers from the base model are not updated\nbase_model.trainable = False\n'''","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.865323Z","iopub.status.idle":"2023-06-11T07:53:00.866148Z","shell.execute_reply.started":"2023-06-11T07:53:00.865905Z","shell.execute_reply":"2023-06-11T07:53:00.865929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install keras-vggface\n!pip install git+https://github.com/rcmalli/keras-vggface.git\n!pip install Keras-Applications\n\n    \nfilename = \"/opt/conda/lib/python3.10/site-packages/keras_vggface/models.py\"\ntext = open(filename).read()\nopen(filename, \"w+\").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))\nimport tensorflow as tf\n\nfrom keras_vggface.vggface import VGGFace\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.867589Z","iopub.status.idle":"2023-06-11T07:53:00.868412Z","shell.execute_reply.started":"2023-06-11T07:53:00.868151Z","shell.execute_reply":"2023-06-11T07:53:00.868173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow as tf\n\nfrom keras_vggface.vggface import VGGFace\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n\n\n\n#from keras_vggface.vggface import VGGFace\n\n# Based on VGG16 architecture -> old paper(2015)\n#vggface = VGGFace(model='vgg16') # or VGGFace() as default\n\n# Based on RESNET50 architecture -> new paper(2017)\nvggface = VGGFace(model='resnet50')\n\n# Based on SENET50 architecture -> new paper(2017)\n#vggface = VGGFace(model='senet50')\n\n\n#from keras.engine import  Model\n#from keras.layers import Input\n#from keras_vggface.vggface import VGGFace\n\n# Convolution Features\n#vgg_features = VGGFace(include_top=False, input_shape=(100, 100, 3), pooling='avg') # pooling: None, avg or max\nvgg_features = VGGFace(include_top=False, input_shape=(224, 224, 3), pooling='avg') # pooling: None, avg or max\n\n# After this point you can use your model to predict.\n# ...\n\n#from keras.engine import  Model\n#from keras.layers import Input\n#from keras_vggface.vggface import VGGFace\n\n# Layer Features\n#layer_name = 'layer_name' # edit this line\n#vgg_model = VGGFace() # pooling: None, avg or max\n#out = vgg_model.get_layer(layer_name).output\n#vgg_model_new = Model(vgg_model.input, out)\n\n# After this point you can use your model to predict.\n# ...\n\n#from keras.engine import  Model\n#from keras.layers import Flatten, Dense, Input\n#from keras_vggface.vggface import VGGFace\n\n#custom parameters\nnb_class = 83\nhidden_dim = 128\n\n#vgg_model = VGGFace(include_top=False, input_shape=(100, 100, 3))\nvgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\nvgg_model.trainable = False\nlast_layer = vgg_model.get_layer('pool5').output\nx = Flatten(name='flatten')(last_layer)\nx = Dense(hidden_dim, activation='relu', name='fc6')(x)\nx = Dense(hidden_dim, activation='relu', name='fc7')(x)\nx = Dropout(0.3)(x)\nout = Dense(nb_class, activation='softmax', name='fc8')(x)\nvggface_model = Model(vgg_model.input, out)\n\n# Train your model as usual.\n# ...\n\n'''\ndef define_vggface_model(input_shape, num_classes):\n    # Load the VGGFace model\n    vggface_model = VGGFace(model='vgg16', weights='vggface', include_top=False, input_shape=input_shape)\n\n    # Freeze the layers of the VGGFace model\n    for layer in vggface_model.layers:\n       layer.trainable = False\n\n    # Flatten the output of the VGGFace model\n    x = Flatten()(vggface_model.output)\n    #x = Flatten()(vggface_model.get_layer('avg_pool').output)\n\n    # Add a fully connected layer with dropout\n    #x = Dense(1024, activation='relu')(x)\n    #x = Dense(512, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.1)(x)\n\n    # Add the output layer for the desired number of classes\n    output = Dense(num_classes, activation='softmax')(x)\n\n    # Create the model\n    model = Model(inputs=vggface_model.input, outputs=output)\n\n    return model\n\n# Define the input shape of your images and the number of classes\ninput_shape = (100, 100, 3)\nnum_classes = 83\n\n# Create the VGGFace transfer learning model\nvggface_model = define_vggface_model(input_shape, num_classes)\n\n'''\n\n# Print a summary of the model architecture\nvggface_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.872575Z","iopub.status.idle":"2023-06-11T07:53:00.873364Z","shell.execute_reply.started":"2023-06-11T07:53:00.873102Z","shell.execute_reply":"2023-06-11T07:53:00.873125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#base_model = VGGFace(model='vgg16', include_top=None,   # we will ignore the top layers that consists of the MLP classifier of VGG16\n                   #weights='vggface', # we will use the weights learned for the ImageNet dataset\n                   #input_shape=(100, 100, 3))  # let's consider a smaller resolution than the original paper due to lack of memory\n\n#base_model.trainable = False\n#vgg_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.874729Z","iopub.status.idle":"2023-06-11T07:53:00.875529Z","shell.execute_reply.started":"2023-06-11T07:53:00.875252Z","shell.execute_reply":"2023-06-11T07:53:00.875289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.87724Z","iopub.status.idle":"2023-06-11T07:53:00.878479Z","shell.execute_reply.started":"2023-06-11T07:53:00.878217Z","shell.execute_reply":"2023-06-11T07:53:00.878244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.879988Z","iopub.status.idle":"2023-06-11T07:53:00.880877Z","shell.execute_reply.started":"2023-06-11T07:53:00.880593Z","shell.execute_reply":"2023-06-11T07:53:00.880616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.2 Define the connected model","metadata":{}},{"cell_type":"code","source":"'''\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\n\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomTranslation\n\nmodel = Sequential([\n    # our base model - feature extraction\n    base_model,\n\n    # data augmentation layers\n#        RandomFlip(\"horizontal\"),\n#        RandomRotation(factor=0.1),\n#        RandomTranslation(height_factor=0.1, width_factor=0.1),\n        \n        # CNN\n#        Conv2D(filters=32, kernel_size=(1,1), activation='relu'),\n#        MaxPool2D(pool_size=(1,1)),\n#        Conv2D(filters=32, kernel_size=(1,1), activation='relu'),\n #       MaxPool2D(pool_size=(1,1)),\n  \n    \n    Flatten(),\n    \n    # FC classifier\n  Dense(512, activation='relu'),\n    # Dense(256, activation='relu'),\n #  Dense(128, activation='relu'),\n  #  Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(83, activation='softmax')\n])\n'''","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.882396Z","iopub.status.idle":"2023-06-11T07:53:00.883202Z","shell.execute_reply.started":"2023-06-11T07:53:00.882946Z","shell.execute_reply":"2023-06-11T07:53:00.882972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vggface_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.88458Z","iopub.status.idle":"2023-06-11T07:53:00.885374Z","shell.execute_reply.started":"2023-06-11T07:53:00.885111Z","shell.execute_reply":"2023-06-11T07:53:00.885135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.886759Z","iopub.status.idle":"2023-06-11T07:53:00.887604Z","shell.execute_reply.started":"2023-06-11T07:53:00.887351Z","shell.execute_reply":"2023-06-11T07:53:00.887375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.3 Compile and run the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n#opt = Adam(learning_rate=0.001)\nopt = Adam(learning_rate=0.0005)\n#model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\nvggface_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:00.888992Z","iopub.status.idle":"2023-06-11T07:53:00.889785Z","shell.execute_reply.started":"2023-06-11T07:53:00.889543Z","shell.execute_reply":"2023-06-11T07:53:00.889567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nearly_stopping_cb = tensorflow.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:01.271742Z","iopub.status.idle":"2023-06-11T07:53:01.272217Z","shell.execute_reply.started":"2023-06-11T07:53:01.272006Z","shell.execute_reply":"2023-06-11T07:53:01.272024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = vggface_model.fit(X_train, y_train, epochs=20, batch_size=83, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])\n# https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n#history = model.fit(training_batch_generator, epochs=20, validation_data=validation_batch_generator, callbacks=[early_stopping_cb],  use_multiprocessing=True, workers=16, max_queue_size=32)\n\n\n#history = vggface_model.fit_generator(training_batch_generator, epochs=20, validation_data=validation_batch_generator, callbacks=[early_stopping_cb],  use_multiprocessing=True, workers=16, max_queue_size=32)\n                    # Used for generator or keras.utils.Sequence input only\n                   ","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:01.273732Z","iopub.status.idle":"2023-06-11T07:53:01.274221Z","shell.execute_reply.started":"2023-06-11T07:53:01.273967Z","shell.execute_reply":"2023-06-11T07:53:01.273989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n# vertical\nplot_model(vggface_model, show_shapes=True, show_layer_activations=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:01.275115Z","iopub.status.idle":"2023-06-11T07:53:01.275551Z","shell.execute_reply.started":"2023-06-11T07:53:01.275326Z","shell.execute_reply":"2023-06-11T07:53:01.275348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creates a HDF5 file\nvggface_model.save('../working/'+\n    'transfer_learning_trained' +\n    '_face_cnn_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:55:13.461111Z","iopub.execute_input":"2023-06-11T07:55:13.461588Z","iopub.status.idle":"2023-06-11T07:55:13.700336Z","shell.execute_reply.started":"2023-06-11T07:55:13.461547Z","shell.execute_reply":"2023-06-11T07:55:13.699366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.4 Visualizing the training history","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nhistory_df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:00:41.790662Z","iopub.execute_input":"2023-06-11T08:00:41.791523Z","iopub.status.idle":"2023-06-11T08:00:41.797345Z","shell.execute_reply.started":"2023-06-11T08:00:41.791471Z","shell.execute_reply":"2023-06-11T08:00:41.796384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\nplt.grid(True)\nplt.xlabel('Epochs')\nplt.ylabel('Score')\n\nhistory_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\nplt.grid(True)\nplt.xlabel('Epochs')\nplt.ylabel('Score')","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:00:55.33843Z","iopub.execute_input":"2023-06-11T08:00:55.33879Z","iopub.status.idle":"2023-06-11T08:00:56.079222Z","shell.execute_reply.started":"2023-06-11T08:00:55.338762Z","shell.execute_reply":"2023-06-11T08:00:56.078137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking class balancing in the training set\n#test_folder = '../input/ifsp-d3apl-2023-face-recognition/test/test/'\n\n#dataset_df_test['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T07:53:01.286285Z","iopub.status.idle":"2023-06-11T07:53:01.286956Z","shell.execute_reply.started":"2023-06-11T07:53:01.286704Z","shell.execute_reply":"2023-06-11T07:53:01.286727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation","metadata":{}},{"cell_type":"code","source":"vggface_model.evaluate(X_test, y_test)\n#model.evaluate(test_batch_generator)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:01:10.435405Z","iopub.execute_input":"2023-06-11T08:01:10.435803Z","iopub.status.idle":"2023-06-11T08:01:17.814315Z","shell.execute_reply.started":"2023-06-11T08:01:10.43577Z","shell.execute_reply":"2023-06-11T08:01:17.81329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_proba = vggface_model.predict(X_test)\n#y_test_proba = model.predict(test_batch_generator)\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:01:21.808374Z","iopub.execute_input":"2023-06-11T08:01:21.808752Z","iopub.status.idle":"2023-06-11T08:01:25.730085Z","shell.execute_reply.started":"2023-06-11T08:01:21.808722Z","shell.execute_reply":"2023-06-11T08:01:25.72903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = np.argmax(y_test_proba, axis=1)\ny_test_pred","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:01:29.672987Z","iopub.execute_input":"2023-06-11T08:01:29.673494Z","iopub.status.idle":"2023-06-11T08:01:29.694952Z","shell.execute_reply.started":"2023-06-11T08:01:29.673454Z","shell.execute_reply":"2023-06-11T08:01:29.693912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_test = label_encoder.transform(dataset_df_test['class'])\nclass_names = label_encoder.classes_\n\nprint(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:01:33.167048Z","iopub.execute_input":"2023-06-11T08:01:33.167437Z","iopub.status.idle":"2023-06-11T08:01:33.18698Z","shell.execute_reply.started":"2023-06-11T08:01:33.167404Z","shell.execute_reply":"2023-06-11T08:01:33.185459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating prediciton file for submission","metadata":{}},{"cell_type":"code","source":"#import os\n\n# checking class balancing in the training set\ntest_folder = '../input/ifsp-d3apl-2023-face-recognition/test/test/'\n\nimg_test_list = sorted(os.listdir(test_folder))\n\nimg_test_full_paths = []\n#img_pred_classes = []\n\nfor img_test in img_test_list:\n    full_img_test_path = os.path.join(test_folder, img_test)\n    img_test_full_paths.append(full_img_test_path)\n\n# creating a dataframe to store the image full pathnames and their corresponding classes\n#import pandas as pd\n\ndataset_sub_test = pd.DataFrame({\n    'image_pathname': img_test_full_paths\n   })\n\ndataset_sub_test\n    \n    # print()\n#print(img_test_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_sub_test['image_pathname'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n\ndef preprocess_faces_dataset(dataset_df, label_encoder: LabelEncoder, new_img_dims=(224, 224), verbose=0):\n    # load the images as a feature matrix\n    image_list = []  # list of numpy arrays\n    \n    for index, img_path in enumerate(dataset_df['image_pathname']):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # image resizing\n        # for gray or color images, the linear interpolation sounds good\n        img = cv2.resize(img, new_img_dims, interpolation=cv2.INTER_LINEAR)        \n        image_list.append(img)\n        \n        if verbose and (index % verbose) == 0:\n            print(f'{index + 1}/{dataset_df.shape[0]} - {img_path}')\n    \n    # numpy array 4D: n_imgs, height, width, n_channels\n    X = np.array(image_list)\n    \n    # feature scaling\n    # numpy arary 4D with values within [0, 1]\n    X = X / 255.0\n    \n    # encoding the classes\n    # numpy array 1D with integer labels\n    #y = label_encoder.transform(dataset_df['class'])\n    \n    return X\n\nx_test=preprocess_faces_dataset(dataset_sub_test, label_encoder, new_img_dims=(224, 224))\nx_test\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nout_dir = '../working/preprocessed'\n\nif not os.path.exists(out_dir):\n    os.makedirs(out_dir)\n    \ndataset_sub_test.to_csv(os.path.join(out_dir, 'sub_test.csv'), index=False)\nnp.save(os.path.join(out_dir, 'test_data_224x224x3.npy'), x_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:05:58.60305Z","iopub.execute_input":"2023-06-11T08:05:58.603475Z","iopub.status.idle":"2023-06-11T08:06:02.256567Z","shell.execute_reply.started":"2023-06-11T08:05:58.603442Z","shell.execute_reply":"2023-06-11T08:06:02.255108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_proba = vggface_model.predict(x_test)\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2023-06-11T08:08:24.68118Z","iopub.execute_input":"2023-06-11T08:08:24.681898Z","iopub.status.idle":"2023-06-11T08:08:34.512031Z","shell.execute_reply.started":"2023-06-11T08:08:24.681863Z","shell.execute_reply":"2023-06-11T08:08:34.511048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = np.argmax(y_test_proba, axis=1)\ny_test_pred\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_test_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nclass_names = label_encoder.classes_\n\n#y_test_pred = label_encoder.transform(dataset_df_test['class'])\n\nle_fitted = le.fit_transform(class_names)\n\ninverted = le.inverse_transform(y_test_pred)\n\nprint(inverted)\nlen(inverted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id=list(range(1661))\nimage_id.pop(0)\nlen(image_id)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_submission = pd.DataFrame({\n    'image-id': image_id,\n    'prediction': inverted\n   })\n\ndataset_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_submission.to_csv('../working/prediction_400.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}